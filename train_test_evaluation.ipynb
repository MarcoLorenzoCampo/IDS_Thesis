{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:28.036402100Z",
     "start_time": "2024-03-08T11:22:26.679187Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.under_sampling import RandomUnderSampler as under_sam\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.metrics import matthews_corrcoef, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Main implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:28.657521500Z",
     "start_time": "2024-03-08T11:22:28.025096500Z"
    }
   },
   "outputs": [],
   "source": [
    "# loading the train set\n",
    "df_train = pd.read_csv('EvalResources/KDDTrain+.txt', sep=\",\", header=None, skipinitialspace = True)\n",
    "df_train = df_train[df_train.columns[:-1]]  # tags column\n",
    "titles = pd.read_csv('EvalResources/Field Names.csv', header=None, skipinitialspace = True)\n",
    "label = pd.Series(['label'], index=[41])\n",
    "titles = pd.concat([titles[0], label])\n",
    "df_train.columns = titles.to_list()\n",
    "df_train = df_train.drop(['num_outbound_cmds'],axis=1)\n",
    "df_train_original = df_train\n",
    "\n",
    "# df_train_original.to_csv('KB Process/NSL-KDD Original Datasets/KDDTrain+_with_labels.txt', index=False)\n",
    "\n",
    "#df_train_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:28.785180400Z",
     "start_time": "2024-03-08T11:22:28.601302500Z"
    }
   },
   "outputs": [],
   "source": [
    "# load test set\n",
    "df_test = pd.read_csv('EvalResources/KDDTest+.txt', sep=\",\", header=None, skipinitialspace = True)\n",
    "df_test_ = df_test.sort_index(axis=1)\n",
    "df_test = df_test[df_test.columns[:-1]]\n",
    "df_test.columns = titles.to_list()\n",
    "df_test = df_test.drop(['num_outbound_cmds'],axis=1)\n",
    "df_test_original = df_test\n",
    "\n",
    "# df_test_original.to_csv('KB Process/NSL-KDD Original Datasets/KDDTest+.txt', index=False)\n",
    "\n",
    "#df_test_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Execution Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:28.790254900Z",
     "start_time": "2024-03-08T11:22:28.714598500Z"
    }
   },
   "outputs": [],
   "source": [
    "EXPORT_MODELS = 0\n",
    "EXPORT_DATASETS = 0\n",
    "EXPORT_PCA = 0\n",
    "EXPORT_ENCODERS = 0\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:28.794852200Z",
     "start_time": "2024-03-08T11:22:28.722729700Z"
    }
   },
   "outputs": [],
   "source": [
    "# list of single attacks \n",
    "dos_attacks = ['back', 'land', 'neptune', 'pod', 'smurf', 'teardrop', 'worm', 'apache2', 'mailbomb', 'processtable', 'udpstorm']\n",
    "probe_attacks = ['ipsweep', 'mscan', 'nmap', 'portsweep', 'saint', 'satan']\n",
    "r2l_attacks = ['guess_passwd', 'ftp_write', 'imap', 'phf', 'multihop', 'warezmaster',\n",
    "                'snmpguess', 'spy', 'warezclient', 'httptunnel', 'named', 'sendmail', 'snmpgetattack', 'xlock', 'xsnoop']\n",
    "u2r_attacks = ['buffer_overflow', 'loadmodule', 'perl', 'ps', 'rootkit', 'sqlattack', 'xterm'] \n",
    "\n",
    "# list of attack classes split according to detection layer\n",
    "dos_probe_list = ['back', 'land', 'neptune', 'pod', 'smurf', 'teardrop', 'ipsweep', 'nmap', 'portsweep', 'satan']\n",
    "dos_probe_test = ['apache2', 'mailbomb', 'processtable', 'udpstorm', 'mscan', 'saint']\n",
    "u2r_r2l_list = ['guess_passwd', 'ftp_write', 'imap', 'phf', 'multihop', 'warezmaster',\n",
    "                'snmpguess', 'spy', 'warezclient', 'buffer_overflow', 'loadmodule', 'rootkit', 'perl']\n",
    "u2r_r2l_test = ['httptunnel', 'named', 'sendmail', 'snmpgetattack', 'xlock', 'xsnoop', 'ps', 'xterm', 'sqlattack']\n",
    "normal_list = ['normal']\n",
    "categorical_features = ['protocol_type', 'service', 'flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:28.811190200Z",
     "start_time": "2024-03-08T11:22:28.729837300Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the features obtained with ICFS for both layer 1 and layer 2\n",
    "with open('KBProcess/AWS Downloads/MinimalFeatures/NSL_features_l1.txt', 'r') as f:\n",
    "    common_features_l1 = f.read().split(',')\n",
    "\n",
    "with open('KBProcess/AWS Downloads/MinimalFeatures/NSL_features_l2.txt', 'r') as f:\n",
    "    common_features_l2 = f.read().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:28.872264400Z",
     "start_time": "2024-03-08T11:22:28.738384900Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_and_validate = copy.deepcopy(df_train_original)\n",
    "df_test = copy.deepcopy(df_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:28.922041600Z",
     "start_time": "2024-03-08T11:22:28.776969400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save all the targets for the dataset\n",
    "\n",
    "y_test_l1 = [1 if x in (dos_attacks+probe_attacks) else 0 for x in df_test['label']]\n",
    "y_test_l2 = [1 if x in (u2r_attacks+r2l_attacks) else 0 for x in df_test['label']]\n",
    "\n",
    "if EXPORT_DATASETS:\n",
    "    np.save(\"EvalResources/AdditionalSets/l1_full_test_targets.npy\", y_test_l1)\n",
    "    np.save(\"EvalResources/AdditionalSets/l2_full_test_targets.npy\", y_test_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:28.972691200Z",
     "start_time": "2024-03-08T11:22:28.784178500Z"
    }
   },
   "outputs": [],
   "source": [
    "# add an additional column to th dataframe to perform splitting\n",
    "\n",
    "attacks = ['dos' if x in dos_attacks else\n",
    "           'probe' if x in probe_attacks else\n",
    "           'u2r' if x in u2r_attacks else\n",
    "           'r2l' if x in r2l_attacks else\n",
    "           'normal' for x in df_train_and_validate['label']]\n",
    "\n",
    "# add the column to the dataframe\n",
    "df_train_and_validate['attacks'] = attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOS PROBE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:29.159329200Z",
     "start_time": "2024-03-08T11:22:28.974727600Z"
    }
   },
   "outputs": [],
   "source": [
    "# split in test and validation set for BOTH layers\n",
    "df_train_original, df_val_original = train_test_split(df_train_and_validate, test_size=0.3, stratify=df_train_and_validate['attacks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame and 'column_name' is the specific column you want to plot\n",
    "plt.hist(df_val_original['attacks'], bins=10)  # Adjust the number of bins as needed\n",
    "plt.xlabel('Values')  # Set x-axis label\n",
    "plt.ylabel('Frequency')  # Set y-axis label\n",
    "plt.title('Histogram of Column')  # Set title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame and 'column_name' is the specific column you want to plot\n",
    "plt.hist(df_train_original['attacks'], bins=10)  # Adjust the number of bins as needed\n",
    "plt.xlabel('Values')  # Set x-axis label\n",
    "plt.ylabel('Frequency')  # Set y-axis label\n",
    "plt.title('Histogram of Column')  # Set title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:29.343133900Z",
     "start_time": "2024-03-08T11:22:29.113528300Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataframes specifically for layer 1\n",
    "df_train = copy.deepcopy(df_train_original)\n",
    "df_val = copy.deepcopy(df_val_original)\n",
    "df_test = copy.deepcopy(df_test_original)\n",
    "\n",
    "# target variables for all layers\n",
    "y_train_full = np.array([1 if x not in normal_list else 0 for x in df_train['label']])\n",
    "y_test_full = np.array([1 if x not in normal_list else 0 for x in df_test['label']])\n",
    "\n",
    "# set the target variables accordingly\n",
    "y_train_l1 = np.array([1 if x in (dos_attacks+probe_attacks) else 0 for x in df_train['label']])\n",
    "y_validate_l1 = np.array([1 if x in (dos_attacks+probe_attacks) else 0 for x in df_val['label']])\n",
    "y_test = np.array([1 if x in (dos_attacks+probe_attacks) else 0 for x in df_test ['label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:29.381711800Z",
     "start_time": "2024-03-08T11:22:29.237786200Z"
    }
   },
   "outputs": [],
   "source": [
    "# this dataframe contains the whole train set \n",
    "df_train = df_train.drop(['label'],axis=1)\n",
    "df_train = df_train.reset_index().drop(['index'], axis=1)\n",
    "#df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:29.456546Z",
     "start_time": "2024-03-08T11:22:29.347913900Z"
    }
   },
   "outputs": [],
   "source": [
    "# this dataframe contains the whole validation set\n",
    "df_val = df_val.drop(['label'],axis=1)\n",
    "df_val = df_val.reset_index().drop(['index'], axis=1)\n",
    "#df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:29.556875700Z",
     "start_time": "2024-03-08T11:22:29.442169300Z"
    }
   },
   "outputs": [],
   "source": [
    "# this dataframe contains the whole test set\n",
    "df_test = df_test.drop(['label'],axis=1)\n",
    "df_test = df_test.reset_index().drop(['index'], axis=1)\n",
    "#df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Using features obtained with a random forest on numerical features only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# List of feature names\n",
    "feature_names_l1 = ['src_bytes', 'logged_in', 'count', 'srv_count', 'srv_serror_rate',\n",
    "       'same_srv_rate', 'diff_srv_rate', 'dst_host_srv_count',\n",
    "       'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
    "       'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n",
    "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
    "       'dst_host_srv_rerror_rate']\n",
    "\n",
    "# Selecting features using loc\n",
    "X_train = df_train.loc[:, feature_names_l1]\n",
    "X_validate = df_val.loc[:, feature_names_l1]\n",
    "X_test = df_test.loc[:, feature_names_l1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:29.638749200Z",
     "start_time": "2024-03-08T11:22:29.568980400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using the features extracted by using the ICFS algorithm\n",
    "X_train = df_train[common_features_l1]\n",
    "X_validate = df_val[common_features_l1]\n",
    "X_test = df_test[common_features_l1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:29.757234500Z",
     "start_time": "2024-03-08T11:22:29.633710800Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2 one-hot encoders, one for the features of layer1 and one for the features of layer2\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "ohe2 = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:29.825971400Z",
     "start_time": "2024-03-08T11:22:29.757234500Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler1 = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:29.935617300Z",
     "start_time": "2024-03-08T11:22:29.820347600Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler2 = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:30.021156200Z",
     "start_time": "2024-03-08T11:22:29.907221700Z"
    }
   },
   "outputs": [],
   "source": [
    "# scaling the train set for layer1\n",
    "df_minmax = scaler1.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(df_minmax, columns=X_train.columns)\n",
    "\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:30.080060800Z",
     "start_time": "2024-03-08T11:22:29.982705Z"
    }
   },
   "outputs": [],
   "source": [
    "# scaling the validation set for layer1\n",
    "df_minmax_val = scaler1.transform(X_validate)\n",
    "X_validate = pd.DataFrame(df_minmax_val, columns=X_validate.columns)\n",
    "\n",
    "#X_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:30.217479300Z",
     "start_time": "2024-03-08T11:22:30.082756700Z"
    }
   },
   "outputs": [],
   "source": [
    "# scaling the test set for layer1\n",
    "df_minmax_test = scaler1.transform(X_test)\n",
    "X_test = pd.DataFrame(df_minmax_test, columns=X_test.columns)\n",
    "\n",
    "#X_vtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:30.390695800Z",
     "start_time": "2024-03-08T11:22:30.200101400Z"
    }
   },
   "outputs": [],
   "source": [
    "# perform One-hot encoding for the train set\n",
    "label_enc = ohe.fit_transform(df_train[categorical_features])\n",
    "label_enc.toarray()\n",
    "new_labels = ohe.get_feature_names_out(categorical_features)\n",
    "df_enc = pd.DataFrame(data=label_enc.toarray(), columns=new_labels)\n",
    "X_train = pd.concat([X_train, df_enc], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:30.490629200Z",
     "start_time": "2024-03-08T11:22:30.347122800Z"
    }
   },
   "outputs": [],
   "source": [
    "# perform One-hot encoding for the validation set\n",
    "label_enc = ohe.transform(df_val[categorical_features])\n",
    "label_enc.toarray()\n",
    "new_labels = ohe.get_feature_names_out(categorical_features)\n",
    "df_enc = pd.DataFrame(data=label_enc.toarray(), columns=new_labels)\n",
    "X_validate = pd.concat([X_validate, df_enc], axis=1)\n",
    "\n",
    "#X_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:30.543296800Z",
     "start_time": "2024-03-08T11:22:30.423257800Z"
    }
   },
   "outputs": [],
   "source": [
    "# perform One-hot encoding for the test set\n",
    "label_enc = ohe.transform(df_test[categorical_features])\n",
    "label_enc.toarray()\n",
    "new_labels = ohe.get_feature_names_out(categorical_features)\n",
    "df_enc = pd.DataFrame(data=label_enc.toarray(), columns=new_labels)\n",
    "X_test = pd.concat([X_test, df_enc], axis=1)\n",
    "\n",
    "#X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:30.599515400Z",
     "start_time": "2024-03-08T11:22:30.487153800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the whole train set:  (88181, 99)\n",
      "Shape of its targets:  (88181,)\n",
      "Shape of the whole train set:  (37792, 99)\n",
      "Shape of its targets:  (37792,)\n",
      "Shape of the whole test set:  (22544, 99)\n",
      "Shape of its targets:  (22544,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of the whole train set: ', X_train.shape)\n",
    "print('Shape of its targets: ', y_train_l1.shape)\n",
    "print('Shape of the whole train set: ', X_validate.shape)\n",
    "print('Shape of its targets: ', y_validate_l1.shape)\n",
    "print('Shape of the whole test set: ', X_test.shape)\n",
    "print('Shape of its targets: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Export the dataset for training layer 1\n",
    "if EXPORT_DATASETS:\n",
    "    X_train.to_csv('EvalResources/ProcessedDatasets/x_train_l1.txt', index=False)\n",
    "    X_validate.to_csv('EvalResources/ProcessedDatasets/x_val_l1.txt', index=False)\n",
    "    np.save('EvalResources/ProcessedWithPCA/y_train_l1', y_train_l1)\n",
    "    np.save('EvalResources/ProcessedWithPCA/y_val_l1', y_validate_l1)\n",
    "    np.save('EvalResources/ProcessedWithPCA/y_test_l1', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:31.994911Z",
     "start_time": "2024-03-08T11:22:30.591045500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(88181, 28)"
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_dos_probe = PCA(n_components=0.95)\n",
    "X_train_dos_probe = pca_dos_probe.fit_transform(X_train)\n",
    "X_test_dos_probe = pca_dos_probe.transform(X_test)\n",
    "X_validate_dos_probe = pca_dos_probe.transform(X_validate)\n",
    "\n",
    "# X_train = X_train.sort_index(axis=1)\n",
    "X_train_dos_probe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "if EXPORT_PCA:\n",
    "    # save the pca transformed datasets for layer1\n",
    "    column_names = [f'PC{i}' for i in range(1, X_test_dos_probe.shape[1] + 1)]\n",
    "    x = pd.DataFrame(data=X_test_dos_probe, columns=column_names)\n",
    "    x.to_csv('EvalResources/ProcessedDatasets/KDDTest+_l1_pca.txt', index=False)\n",
    "    \n",
    "    column_names = [f'PC{i}' for i in range(1, X_train_dos_probe.shape[1] + 1)]\n",
    "    x = pd.DataFrame(data=X_train_dos_probe, columns=column_names)\n",
    "    x.to_csv('EvalResources/ProcessedDatasets/KDDTrain+_l1_pca.txt', index=False)\n",
    "    \n",
    "    column_names = [f'PC{i}' for i in range(1, X_validate_dos_probe.shape[1] + 1)]\n",
    "    x = pd.DataFrame(data=X_validate_dos_probe, columns=column_names)\n",
    "    x.to_csv('EvalResources/ProcessedDatasets/KDDValidate+_l1_pca.txt', index=False)\n",
    "    \n",
    "    # save the correspondant target values\n",
    "    np.save(\"EvalResources/ProcessedDatasets//KDDTrain+_l1_targets\", y_train_l1)\n",
    "    np.save(\"EvalResources/ProcessedDatasets/KDDValidate+_l1_targets\", y_validate_l1)\n",
    "    np.save(\"EvalResources/ProcessedDatasets//KDDTest+_l1_targets\", y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Building the classifier for the layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:32.011812300Z",
     "start_time": "2024-03-08T11:22:31.963933900Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:32.258198900Z",
     "start_time": "2024-03-08T11:22:31.969018900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Voting classifiers\n",
    "\n",
    "voting_classifiers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "# Using HistGradientBoosting classifier\n",
    "dos_probe_classifier = HistGradientBoostingClassifier()\n",
    "\n",
    "start = datetime.now()\n",
    "dos_probe_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "ttime = datetime.now() - start\n",
    "\n",
    "\n",
    "voting_classifiers.append((\"hgbc\", dos_probe_classifier))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:34.024249300Z",
     "start_time": "2024-03-08T11:22:32.016008300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using Random Forest Classifier\n",
    "dos_probe_classifier = RandomForestClassifier()\n",
    "\n",
    "start = datetime.now()\n",
    "dos_probe_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "ttime = datetime.now() - start\n",
    "\n",
    "voting_classifiers.append((\"rf\", dos_probe_classifier))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "predicted = dos_probe_classifier.predict(X_test_dos_probe)\n",
    "\n",
    "print('Metrics for layer 1:')\n",
    "print('Confusion matrix: [TP FN / FP TN]\\n', confusion_matrix(y_test,predicted))\n",
    "print('Accuracy = ', accuracy_score(y_test,predicted))\n",
    "print('F1 Score = ', f1_score(y_test,predicted))\n",
    "print('Precision = ', precision_score(y_test,predicted))\n",
    "print('Recall = ', recall_score(y_test,predicted))\n",
    "print('Train time = ', ttime)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# test the other classifiers obtained in the evaluation phase\n",
    "dos_probe_classifier = joblib.load(\"TunerProcess/TunedModels/l1_classifier.pkl\")\n",
    "#classifier2 = joblib.load(\"TunerProcess/TunedModels/l1_classifier.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using the Naive Bayes Classifier\n",
    "dos_probe_classifier = GaussianNB()\n",
    "\n",
    "voting_classifiers.append((\"nbc\", dos_probe_classifier))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "start = datetime.now()\n",
    "dos_probe_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "ttime = datetime.now() - start\n",
    "\n",
    "predicted = dos_probe_classifier.predict(X_test_dos_probe)\n",
    "\n",
    "print('Metrics for layer 1:')\n",
    "print('Confusion matrix: [TP FN / FP TN]\\n', confusion_matrix(y_test,predicted))\n",
    "print('Accuracy = ', accuracy_score(y_test,predicted))\n",
    "print('F1 Score = ', f1_score(y_test,predicted))\n",
    "print('Precision = ', precision_score(y_test,predicted))\n",
    "print('Recall = ', recall_score(y_test,predicted))\n",
    "print('Train time = ', ttime)\n",
    "print('Shape of the train set for l1: ', X_train_dos_probe.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Voting classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "dos_probe_classifier = VotingClassifier(estimators=voting_classifiers, voting='soft')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "start = datetime.now()\n",
    "dos_probe_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "ttime = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "predicted = dos_probe_classifier.predict(X_test_dos_probe)\n",
    "\n",
    "print('Using a voting classifier:')\n",
    "print('Confusion matrix: [TP FN / FP TN]\\n', confusion_matrix(y_test,predicted))\n",
    "print('Accuracy = ', accuracy_score(y_test,predicted))\n",
    "print('F1 Score = ', f1_score(y_test,predicted))\n",
    "print('Precision = ', precision_score(y_test,predicted))\n",
    "print('Recall = ', recall_score(y_test,predicted))\n",
    "print('Train time = ', ttime)\n",
    "print('Shape of the train set for l1: ', X_train_dos_probe.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R2L+U2R classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:34.160702200Z",
     "start_time": "2024-03-08T11:22:33.956653500Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = copy.deepcopy(df_train_original)\n",
    "df_test = copy.deepcopy(df_test_original)\n",
    "df_val = copy.deepcopy(df_val_original)\n",
    "\n",
    "# load targeted attacks (Normal + r2l + u2r)\n",
    "df_train = df_train[df_train['label'].isin(normal_list+u2r_attacks+r2l_attacks)]\n",
    "df_val = df_val[df_val['label'].isin(normal_list+u2r_attacks+r2l_attacks)]\n",
    "df_test = df_test[df_test['label'].isin(normal_list+u2r_attacks+r2l_attacks)]\n",
    "\n",
    "# set the target variables accordingly\n",
    "y_train_l2 = np.array([1 if x in (u2r_attacks+r2l_attacks) else 0 for x in df_train['label']])\n",
    "y_validate_l2 = np.array([1 if x in (u2r_attacks+r2l_attacks) else 0 for x in df_val['label']])\n",
    "y_test = np.array([1 if x in (u2r_attacks+r2l_attacks) else 0 for x in df_test['label']])\n",
    "\n",
    "df_train = df_train.drop(['label'],axis=1)\n",
    "df_train = df_train.reset_index().drop(['index'], axis=1)\n",
    "#df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:34.177481400Z",
     "start_time": "2024-03-08T11:22:34.079019Z"
    }
   },
   "outputs": [],
   "source": [
    "df_val = df_val.drop(['label'],axis=1)\n",
    "df_val = df_val.reset_index().drop(['index'], axis=1)\n",
    "#df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:34.237685700Z",
     "start_time": "2024-03-08T11:22:34.095756200Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = df_test.drop(['label'],axis=1)\n",
    "df_test = df_test.reset_index().drop(['index'], axis=1)\n",
    "#df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:34.242359600Z",
     "start_time": "2024-03-08T11:22:34.115249600Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df_train\n",
    "X_validate = df_val\n",
    "X_test = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Using features obtained with a random forest on numerical features only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# List of feature names\n",
    "feature_names_l2 = ['count', 'is_guest_login', 'srv_count', 'hot', 'dst_host_serror_rate',\n",
    "       'dst_host_srv_count', 'dst_host_count', 'dst_host_same_srv_rate',\n",
    "       'dst_host_same_src_port_rate', 'num_file_creations', 'diff_srv_rate']\n",
    "\n",
    "# Selecting features using loc\n",
    "X_train = df_train.loc[:, feature_names_l2]\n",
    "X_validate = df_val.loc[:, feature_names_l2]\n",
    "X_test = df_test.loc[:, feature_names_l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:34.266770300Z",
     "start_time": "2024-03-08T11:22:34.119192500Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df_train[common_features_l2]\n",
    "X_validate = df_val[common_features_l2]\n",
    "X_test = df_test[common_features_l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:34.311146800Z",
     "start_time": "2024-03-08T11:22:34.130526500Z"
    }
   },
   "outputs": [],
   "source": [
    "df_minmax = scaler2.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(df_minmax, columns=X_train.columns)\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:34.314282800Z",
     "start_time": "2024-03-08T11:22:34.147133800Z"
    }
   },
   "outputs": [],
   "source": [
    "df_minmax = scaler2.transform(X_validate)\n",
    "X_validate = pd.DataFrame(df_minmax, columns=X_validate.columns)\n",
    "#X_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:34.369377600Z",
     "start_time": "2024-03-08T11:22:34.159631200Z"
    }
   },
   "outputs": [],
   "source": [
    "df_minmax = scaler2.transform(X_test)\n",
    "X_test = pd.DataFrame(df_minmax, columns=X_test.columns)\n",
    "#X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:34.391253100Z",
     "start_time": "2024-03-08T11:22:34.169762Z"
    }
   },
   "outputs": [],
   "source": [
    "# perform One-hot encoding for the train set\n",
    "label_enc = ohe2.fit_transform(df_train[categorical_features])\n",
    "label_enc.toarray()\n",
    "new_labels = ohe2.get_feature_names_out(categorical_features)\n",
    "df_enc = pd.DataFrame(data=label_enc.toarray(), columns=new_labels)\n",
    "X_train = pd.concat([X_train, df_enc], axis=1)\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:34.528459500Z",
     "start_time": "2024-03-08T11:22:34.225728800Z"
    }
   },
   "outputs": [],
   "source": [
    "# perform One-hot encoding for the validation set\n",
    "label_enc = ohe2.transform(df_val[categorical_features])\n",
    "label_enc.toarray()\n",
    "new_labels = ohe2.get_feature_names_out(categorical_features)\n",
    "df_enc = pd.DataFrame(data=label_enc.toarray(), columns=new_labels)\n",
    "X_validate = pd.concat([X_validate, df_enc], axis=1)\n",
    "#X_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:34.565261800Z",
     "start_time": "2024-03-08T11:22:34.261759Z"
    }
   },
   "outputs": [],
   "source": [
    "# perform One-hot encoding for the test set\n",
    "label_enc = ohe2.transform(df_test[categorical_features])\n",
    "label_enc.toarray()\n",
    "new_labels = ohe2.get_feature_names_out(categorical_features)\n",
    "df_enc = pd.DataFrame(data=label_enc.toarray(), columns=new_labels)\n",
    "X_test = pd.concat([X_test, df_enc], axis=1)\n",
    "#X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:34.570975600Z",
     "start_time": "2024-03-08T11:22:34.288021200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train set:  (47873, 51)\n",
      "Shape of its target:  (47873,)\n",
      "Shape of the test set:  (12663, 51)\n",
      "Shape of its target:  (12663,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of the train set: ', X_train.shape)\n",
    "print('Shape of its target: ', y_train_l2.shape)\n",
    "print('Shape of the test set: ', X_test.shape)\n",
    "print('Shape of its target: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:34.614379600Z",
     "start_time": "2024-03-08T11:22:34.295268700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Under sampling the train set for l2\n",
    "sm = under_sam(sampling_strategy=1)\n",
    "X_train, y_train_l2 = sm.fit_resample(X_train,y_train_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Under sampling the validation set for l2\n",
    "sm = under_sam(sampling_strategy=1)\n",
    "X_validate, y_validate_l2 = sm.fit_resample(X_validate,y_validate_l2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Export the datasets\n",
    "Train set has been scaled, one hot encoded, undersampled\n",
    "Test set has been scaled and one hot encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Export the dataset for training layer 2\n",
    "if EXPORT_DATASETS:\n",
    "    # X_train.to_csv('EvalResources/ProcessedDatasets/x_train_l2.txt', index=False)\n",
    "    np.save('EvalResources/ProcessedWithPCA/y_train_l2', y_train_l2)\n",
    "    # X_validate.to_csv('EvalResources/ProcessedDatasets/x_val_l2.txt', index=False)\n",
    "    np.save('EvalResources/ProcessedWithPCA/y_val_l2', y_val)\n",
    "    np.save('EvalResources/ProcessedWithPCA/y_test_l2', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:34.677573800Z",
     "start_time": "2024-03-08T11:22:34.348295300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Principal Component Analysis\n",
    "pca_r2l_u2r = PCA(n_components=0.95)\n",
    "X_train_r2l_u2r = pca_r2l_u2r.fit_transform(X_train)\n",
    "X_test_r2l_u2r = pca_r2l_u2r.transform(X_test)\n",
    "X_validate_r2l_u2r = pca_r2l_u2r.transform(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:34.710066300Z",
     "start_time": "2024-03-08T11:22:34.387062800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Support Vector Machine for layer l2\n",
    "r2l_u2r_classifier = SVC(probability=True)\n",
    "\n",
    "#r2l_u2r_classifier = SVC()\n",
    "\n",
    "start = datetime.now()\n",
    "r2l_u2r_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "ttime = datetime.now() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "predicted = r2l_u2r_classifier.predict(X_test_r2l_u2r)\n",
    "\n",
    "print('Metrics for layer 2:')\n",
    "print('Confusion matrix: [TP FN / FP TN]\\n', confusion_matrix(y_test,predicted))\n",
    "print('Accuracy = ', accuracy_score(y_test,predicted))\n",
    "print('F1 Score = ', f1_score(y_test,predicted))\n",
    "print('Precision = ', precision_score(y_test,predicted))\n",
    "print('Recall = ', recall_score(y_test,predicted))\n",
    "print('Matthew corr = ', matthews_corrcoef(y_test,predicted))\n",
    "print('Train time = ', ttime)\n",
    "print('Shape of the training set: ', X_train_r2l_u2r.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "predicted = r2l_u2r_classifier.predict(X_train_r2l_u2r)\n",
    "\n",
    "print('Metrics for layer 2:')\n",
    "print('Confusion matrix: [TP FN / FP TN]\\n', confusion_matrix(y_train_l2,predicted))\n",
    "print('Accuracy = ', accuracy_score(y_train_l2,predicted))\n",
    "print('F1 Score = ', f1_score(y_train_l2,predicted))\n",
    "print('Precision = ', precision_score(y_train_l2,predicted))\n",
    "print('Recall = ', recall_score(y_train_l2,predicted))\n",
    "print('Matthew corr = ', matthews_corrcoef(y_train_l2,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "if EXPORT_PCA:\n",
    "    # save the pca transformed as well as the transformer\n",
    "    column_names = [f'PC{i}' for i in range(1, X_test_r2l_u2r.shape[1] + 1)]\n",
    "    x = pd.DataFrame(data=X_test_r2l_u2r, columns=column_names)\n",
    "    x.to_csv('EvalResources/ProcessedDatasets/KDDTest+_l2_pca.txt', index=False)\n",
    "    \n",
    "    column_names = [f'PC{i}' for i in range(1, X_train_r2l_u2r.shape[1] + 1)]\n",
    "    x = pd.DataFrame(data=X_train_r2l_u2r, columns=column_names)\n",
    "    x.to_csv('EvalResources/ProcessedDatasets/KDDTrain+_l2_pca.txt', index=False)\n",
    "    \n",
    "    column_names = [f'PC{i}' for i in range(1, X_validate_r2l_u2r.shape[1] + 1)]\n",
    "    x = pd.DataFrame(data=X_validate_r2l_u2r, columns=column_names)\n",
    "    x.to_csv('EvalResources/ProcessedDatasets/KDDValidate+_l2_pca.txt', index=False)\n",
    "\n",
    "    # export the correspondant targets values\n",
    "    np.save(\"EvalResources/ProcessedDatasets//KDDTrain+_l2_targets\", y_train_l2)\n",
    "    np.save(\"EvalResources/ProcessedDatasets/KDDValidate+_l2_targets\", y_validate_l2)\n",
    "    np.save(\"EvalResources/ProcessedDatasets//KDDTest+_l2_targets\", y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Export the classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "if EXPORT_MODELS:\n",
    "    with open('EvalResources/Models/HGBC/l1_classifier.pkl', \"wb\") as f:\n",
    "        pickle.dump(dos_probe_classifier, f)\n",
    "    with open('EvalResources/Models/HGBC/l2_classifier.pkl', \"wb\") as f:\n",
    "        pickle.dump(r2l_u2r_classifier, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Export one hot encoders\n",
    "if EXPORT_ENCODERS:\n",
    "    joblib.dump(ohe, 'EvalResources/Encoders/ohe_l1.pkl')\n",
    "    joblib.dump(ohe2, 'EvalResources/Encoders/ohe_l2.pkl')\n",
    "    joblib.dump(scaler1, 'EvalResources/Encoders/Scaler_l1.pkl')\n",
    "    joblib.dump(scaler2, 'EvalResources/Encoders/Scaler_l2.pkl')\n",
    "    joblib.dump(pca_dos_probe, 'EvalResources/Encoders/pca_transformer_l1.pkl')\n",
    "    joblib.dump(pca_r2l_u2r, 'EvalResources/Encoders/pca_transformer_l2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:34.731330600Z",
     "start_time": "2024-03-08T11:22:34.496429900Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test1 = copy.deepcopy(df_test_original)\n",
    "df_test2 = copy.deepcopy(df_test_original)\n",
    "\n",
    "y_test_real = np.array([0 if x=='normal' else 1 for x in df_test1['label']])\n",
    "\n",
    "np.save(\"EvalResources/Test/KDDTest+_targets\", y_test_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:34.944683900Z",
     "start_time": "2024-03-08T11:22:34.513629100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(22544,)"
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_real.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "X_test1 = df_test1.loc[:, feature_names_l1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:34.989759Z",
     "start_time": "2024-03-08T11:22:34.524579Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test1 = df_test1[common_features_l1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:35.059685900Z",
     "start_time": "2024-03-08T11:22:34.535199900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set shape for layer 1:  (22544, 28)\n"
     ]
    }
   ],
   "source": [
    "df_minmax = scaler1.transform(X_test1)\n",
    "X_test1 = pd.DataFrame(df_minmax, columns=X_test1.columns)\n",
    "label_enc = ohe.transform(df_test1.iloc[:,1:4])\n",
    "label_enc.toarray()\n",
    "new_labels = ohe.get_feature_names_out(categorical_features)\n",
    "df_enc = pd.DataFrame(data=label_enc.toarray(), columns=new_labels)\n",
    "X_test1 = pd.concat([X_test1, df_enc], axis=1)\n",
    "\n",
    "X_test_layer1 = pca_dos_probe.transform(X_test1)\n",
    "print('Test set shape for layer 1: ', X_test_layer1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:35.075300400Z",
     "start_time": "2024-03-08T11:22:34.604491Z"
    }
   },
   "outputs": [],
   "source": [
    "#X_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:35.082386300Z",
     "start_time": "2024-03-08T11:22:34.610184700Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test2 = df_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "X_test2 = df_test2.loc[:, feature_names_l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:35.087218800Z",
     "start_time": "2024-03-08T11:22:34.620361900Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test2 = df_test2[common_features_l2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:35.146443500Z",
     "start_time": "2024-03-08T11:22:34.626370900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set shape for layer 1:  (22544, 28)\n",
      "Test set shape for layer 2:  (22544, 14)\n"
     ]
    }
   ],
   "source": [
    "df_minmax = scaler2.transform(X_test2)\n",
    "X_test2 = pd.DataFrame(df_minmax, columns=X_test2.columns)\n",
    "label_enc = ohe2.transform(df_test2.iloc[:,1:4])\n",
    "label_enc.toarray()\n",
    "new_labels = ohe2.get_feature_names_out(categorical_features)\n",
    "df_enc = pd.DataFrame(data=label_enc.toarray(), columns=new_labels)\n",
    "X_test2 = pd.concat([X_test2, df_enc], axis=1)\n",
    "\n",
    "X_test_layer2 = pca_r2l_u2r.transform(X_test2)\n",
    "print('Test set shape for layer 1: ', X_test_layer1.shape)\n",
    "print('Test set shape for layer 2: ', X_test_layer2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:35.163931600Z",
     "start_time": "2024-03-08T11:22:34.681339600Z"
    }
   },
   "outputs": [],
   "source": [
    "#X_test_layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:35.169104400Z",
     "start_time": "2024-03-08T11:22:34.685862Z"
    }
   },
   "outputs": [],
   "source": [
    "#X_test_layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:35.185061300Z",
     "start_time": "2024-03-08T11:22:34.692067Z"
    }
   },
   "outputs": [],
   "source": [
    "# same classifiers obtained above\n",
    "classifier1 = dos_probe_classifier\n",
    "classifier2 = r2l_u2r_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:22:35.206718800Z",
     "start_time": "2024-03-08T11:22:34.702831400Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppressing the warning\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names.*\")\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def test_metrics():\n",
    "    result_ = []\n",
    "    tn, fp, fn, tp = 0, 0, 0, 0\n",
    "    \n",
    "    start_ = datetime.now()\n",
    "    \n",
    "    for i in range(X_test_layer2.shape[0]):\n",
    "        layer1_ = classifier1.predict(X_test_layer1[i].reshape(1, -1))[0]\n",
    "        if layer1_ == 1:\n",
    "            result_.append(layer1_)\n",
    "        else:\n",
    "            layer2_ = classifier2.predict(X_test_layer2[i].reshape(1, -1))[0]\n",
    "            if layer2_ == 1:\n",
    "                result_.append(layer2_)\n",
    "            else:\n",
    "                result_.append(0)\n",
    "        # Evaluate confusion matrix\n",
    "        if y_test_real[i] == 1:\n",
    "            if result_[-1] == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "        else:\n",
    "            if result_[-1] == 1:\n",
    "                fp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "    \n",
    "    clf_time_ = datetime.now() - start_\n",
    "    \n",
    "    # Calculate rates\n",
    "    tnr_ = tn / (tn + fp)\n",
    "    fpr_= fp / (fp + tn)\n",
    "    fnr_ = fn / (fn + tp)\n",
    "    \n",
    "    return (accuracy_score(y_test_real,np.array(result_)), \n",
    "            f1_score(y_test_real, np.array(result_)),\n",
    "            precision_score(y_test_real, np.array(result_)),\n",
    "            recall_score(y_test_real, np.array(result_)),\n",
    "            clf_time_, tnr_, fpr_, fnr_, np.array(result_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.8499822569198012\n",
      "F1 Score =  0.8531225571093546\n",
      "Precision =  0.9636024722849014\n",
      "Recall =  0.7653705291046521\n",
      "Classification time =  0:00:40.172385\n",
      "False Positive Rate (FPR) = 0.0382040984450623\n",
      "True Negative Rate (TNR) = 0.9617959015549377\n",
      "False Negative Rate (FNR) = 0.23462947089534794\n"
     ]
    }
   ],
   "source": [
    "# the results may vary\n",
    "accuracy, f_score, precision, recall, clf_time, tnr, fpr, fnr, result = test_metrics()\n",
    "\n",
    "print('Accuracy = ', accuracy)\n",
    "print('F1 Score = ', f_score)\n",
    "print('Precision = ', precision)\n",
    "print('Recall = ', recall)\n",
    "print('Classification time = ', clf_time)\n",
    "print('False Positive Rate (FPR) =', fpr)\n",
    "print('True Negative Rate (TNR) =', tnr)\n",
    "print('False Negative Rate (FNR) =', fnr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T11:23:14.933148500Z",
     "start_time": "2024-03-08T11:22:34.716951900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run the function multiple times and accumulate results\n",
    "num_iterations = 5\n",
    "total_accuracy = 0\n",
    "total_f1_score = 0\n",
    "total_precision = 0\n",
    "total_recall = 0\n",
    "total_clf_time = 0\n",
    "total_tnr = 0\n",
    "total_fpr = 0\n",
    "total_fnr = 0\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    acc, f1, prec, rec, clf_time, tnr, fpr, fnr, _ = test_metrics()\n",
    "    total_accuracy += acc\n",
    "    total_f1_score += f1\n",
    "    total_precision += prec\n",
    "    total_recall += rec\n",
    "    total_tnr += tnr\n",
    "    total_fpr += fpr\n",
    "    total_fnr += fnr\n",
    "\n",
    "# Calculate averages\n",
    "avg_accuracy = total_accuracy / num_iterations\n",
    "avg_f1_score = total_f1_score / num_iterations\n",
    "avg_precision = total_precision / num_iterations\n",
    "avg_recall = total_recall / num_iterations\n",
    "avg_tnr = total_tnr / num_iterations\n",
    "avg_fpr = total_fpr / num_iterations\n",
    "avg_fnr = total_fnr / num_iterations\n",
    "\n",
    "print('Average Accuracy:', avg_accuracy)\n",
    "print('Average F1 Score:', avg_f1_score)\n",
    "print('Average Precision:', avg_precision)\n",
    "print('Average Recall:', avg_recall)\n",
    "print('Average TNR:', avg_tnr)\n",
    "print('Average FPR:', avg_fpr)\n",
    "print('Average FNR:', avg_fnr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new attacks in the test set:  3750\n",
      "Number of new attacks detected by the classifiers:  1986\n",
      "Proportion of new attacks detected:  0.5296\n",
      "Number of old attacks in the test set:  9083\n",
      "Number of old attacks detected by the classifiers:  7836\n",
      "Proportion of old attacks detected:  0.8627105581856215\n"
     ]
    }
   ],
   "source": [
    "# load testset\n",
    "df_test = pd.read_csv('EvalResources/KDDTest+.txt', sep=\",\", header=None, skipinitialspace=True)\n",
    "df_test = df_test[df_test.columns[:-1]]\n",
    "df_test.columns = titles.to_list()\n",
    "y_test = df_test['label']\n",
    "df_test = df_test.drop(['num_outbound_cmds'], axis=1)\n",
    "\n",
    "df_test_original = df_test\n",
    "if EXPORT_DATASETS:\n",
    "    df_test_original.to_csv('EvalResources/ProcessedDatasets/x_test_full.txt', index=False)\n",
    "    np.save('EvalResources/ProcessedDatasets/y_test_full', y_test)\n",
    "\n",
    "#df_test_original\n",
    "new_attack = []\n",
    "for i in df_test_original['label'].value_counts().index.tolist()[1:]:\n",
    "    if i not in df_train_original['label'].value_counts().index.tolist()[1:]:\n",
    "        new_attack.append(i)\n",
    "\n",
    "new_attack.sort()\n",
    "#new_attack\n",
    "index_of_new_attacks = []\n",
    "\n",
    "for i in range(len(df_test_original)):\n",
    "    if df_test_original['label'][i] in new_attack:\n",
    "        index_of_new_attacks.append(df_test_original.index[i])\n",
    "\n",
    "new_attack.append('normal')\n",
    "\n",
    "index_of_old_attacks = []\n",
    "\n",
    "for i in range(len(df_test_original)):\n",
    "    if df_test_original['label'][i] not in new_attack:\n",
    "        index_of_old_attacks.append(df_test_original.index[i])\n",
    "print('Number of new attacks in the test set: ', result[index_of_new_attacks].shape[0])\n",
    "print('Number of new attacks detected by the classifiers: ', result[index_of_new_attacks].sum())\n",
    "print('Proportion of new attacks detected: ',\n",
    "      result[index_of_new_attacks].sum() / result[index_of_new_attacks].shape[0])\n",
    "print('Number of old attacks in the test set: ', result[index_of_old_attacks].shape[0])\n",
    "print('Number of old attacks detected by the classifiers: ', result[index_of_old_attacks].sum())\n",
    "print('Proportion of old attacks detected: ',\n",
    "      result[index_of_old_attacks].sum() / result[index_of_old_attacks].shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T11:23:15.355830800Z",
     "start_time": "2024-03-08T11:23:14.925880800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of DOS detection:  0.8517426273458445\n",
      "Ratio of PROBE detection:  0.8558446922759191\n",
      "Ratio of U2R detection:  0.464471403812825\n",
      "Ratio of R2L detection:  0.835820895522388\n",
      "New attacks detected:  0.5296\n",
      "Old attacks detected:  0.8627105581856215\n"
     ]
    }
   ],
   "source": [
    "### Evaluate single attack types\n",
    "# load test set\n",
    "df_test = pd.read_csv('EvalResources/KDDTest+.txt', sep=\",\", header=None, skipinitialspace=True)\n",
    "df_test = df_test[df_test.columns[:-1]]\n",
    "df_test.columns = titles.to_list()\n",
    "y_test = df_test['label']\n",
    "df_test = df_test.drop(['num_outbound_cmds'], axis=1)\n",
    "df_test_original = df_test\n",
    "df = df_test_original\n",
    "\n",
    "dos_index = df.index[(df['label'].isin(dos_attacks))].tolist()\n",
    "probe_index = df.index[(df['label'].isin(probe_attacks))].tolist()\n",
    "r2l_index = df.index[(df['label'].isin(r2l_attacks))].tolist()\n",
    "u2r_index = df.index[(df['label'].isin(u2r_attacks))].tolist()\n",
    "\n",
    "print(\"Ratio of DOS detection: \", result[dos_index].sum() / result[dos_index].shape[0])\n",
    "\n",
    "print(\"Ratio of PROBE detection: \", result[probe_index].sum() / result[probe_index].shape[0])\n",
    "\n",
    "print(\"Ratio of U2R detection: \", result[r2l_index].sum() / result[r2l_index].shape[0])\n",
    "\n",
    "print(\"Ratio of R2L detection: \", result[u2r_index].sum() / result[u2r_index].shape[0])\n",
    "\n",
    "print('New attacks detected: ',\n",
    "      result[index_of_new_attacks].sum() / result[index_of_new_attacks].shape[0])\n",
    "\n",
    "print('Old attacks detected: ',\n",
    "      result[index_of_old_attacks].sum() / result[index_of_old_attacks].shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T11:23:15.438892700Z",
     "start_time": "2024-03-08T11:23:15.359865900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Now start the adaptation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:24:41.046026100Z",
     "start_time": "2024-03-08T11:24:40.461829600Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S1 RF + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the space of hyperparameters for Random Forest\n",
    "rf_params = {\n",
    "    'n_estimators': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_split': optuna.distributions.IntDistribution(2, 20),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "## Define the space of hyperparameters for SVM\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for Random Forest\n",
    "    rf_hyperparams = {\n",
    "        'n_estimators': trial.suggest_int('rf_n_estimators', 10, 70),\n",
    "        'max_depth': trial.suggest_int('rf_max_depth', 2, 32),\n",
    "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize and train Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(**rf_hyperparams)\n",
    "    rf_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    rf_predicted = rf_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    rf_precision = precision_score(y_validate_l1, rf_predicted)\n",
    "    svm_precision = precision_score(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    rf_recall = recall_score(y_validate_l1, rf_predicted)\n",
    "    svm_recall = recall_score(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate weighted average of TPR and Precision (you can adjust weights based on preference)\n",
    "    weighted_score = (0.5 * (rf_recall + svm_recall)) + (0.5 * (rf_precision + svm_precision))\n",
    "    \n",
    "    return weighted_score\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S1 (RF+NBC) + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "rf_params = {\n",
    "    'n_estimators': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_split': optuna.distributions.IntDistribution(2, 20),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "nbc_params = {\n",
    "    'var_smoothing': optuna.distributions.FloatDistribution(1e-10, 1e-1)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for Random Forest\n",
    "    rf_hyperparams = {\n",
    "        'n_estimators': trial.suggest_int('rf_n_estimators', 10, 70),\n",
    "        'max_depth': trial.suggest_int('rf_max_depth', 2, 32),\n",
    "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \n",
    "    \"\"\"\n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for GaussianNB\n",
    "    gnb_hyperparams = {\n",
    "        'var_smoothing': trial.suggest_float('gnb_var_smoothing', 1e-10, 1e-1, log=True)\n",
    "    }\n",
    "    \n",
    "    # Initialize the rf\n",
    "    rf_classifier = RandomForestClassifier(**rf_hyperparams)\n",
    "    \n",
    "    # Initialize the nbc\n",
    "    nbc_classifier = GaussianNB(**gnb_hyperparams)\n",
    "    \n",
    "    # Initialize and train voting classifier\n",
    "    voting_classifier = VotingClassifier(\n",
    "        estimators=[(\"rf\", rf_classifier), (\"nbc\", nbc_classifier)] ,\n",
    "        voting='soft'\n",
    "    )\n",
    "    voting_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    voting_predicted = voting_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    voting_precision = precision_score(y_validate_l1, voting_predicted)\n",
    "    svm_precision = precision_score(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    voting_recall = recall_score(y_validate_l1, voting_predicted)\n",
    "    svm_recall = recall_score(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate weighted average of TPR and Precision (you can adjust weights based on preference)\n",
    "    weighted_score = (0.5 * (voting_recall + svm_recall)) + (0.5 * (voting_precision + svm_precision))\n",
    "    \n",
    "    return weighted_score\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S1 (HGBC+NBC) + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "hgb_params = {\n",
    "    'learning_rate': optuna.distributions.FloatDistribution(0.001, 0.1),\n",
    "    'max_iter': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "nbc_params = {\n",
    "    'var_smoothing': optuna.distributions.FloatDistribution(1e-10, 1e-1)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for HistGradientBoostingClassifier\n",
    "    hgb_hyperparams = {\n",
    "        'learning_rate': trial.suggest_float('hgb_learning_rate', 0.001, 0.1, log=True),\n",
    "        'max_iter': trial.suggest_int('hgb_max_iter', 50, 500),\n",
    "        'max_depth': trial.suggest_int('hgb_max_depth', 2, 32),\n",
    "        'min_samples_leaf': trial.suggest_int('hgb_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for GaussianNB\n",
    "    gnb_hyperparams = {\n",
    "        'var_smoothing': trial.suggest_float('gnb_var_smoothing', 1e-10, 1e-1, log=True)\n",
    "    }\n",
    "    \n",
    "    # Initialize the hgbc\n",
    "    hgbc_classifier = HistGradientBoostingClassifier(**hgb_hyperparams)\n",
    "    \n",
    "    # Initialize the nbc\n",
    "    nbc_classifier = GaussianNB(**gnb_hyperparams)\n",
    "    \n",
    "    # Initialize and train voting classifier\n",
    "    voting_classifier = VotingClassifier(\n",
    "        estimators=[(\"hgbc\", hgbc_classifier), (\"nbc\", nbc_classifier)] ,\n",
    "        voting='soft'\n",
    "    )\n",
    "    voting_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    voting_predicted = voting_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    voting_precision = precision_score(y_validate_l1, voting_predicted)\n",
    "    svm_precision = precision_score(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    voting_recall = recall_score(y_validate_l1, voting_predicted)\n",
    "    svm_recall = recall_score(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate weighted average of TPR and Precision (you can adjust weights based on preference)\n",
    "    weighted_score = (0.5 * (voting_recall + svm_recall)) + (0.5 * (voting_precision + svm_precision))\n",
    "    \n",
    "    return weighted_score\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S1 HGBC + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-08 12:24:41,041] A new study created in memory with name: no-name-6ec3fbb0-067e-462a-8801-b7dfeca7e78d\n",
      "[I 2024-03-08 12:24:49,327] Trial 4 finished with value: 1.9321083527989558 and parameters: {'hgb_learning_rate': 0.018222099550597826, 'hgb_max_iter': 211, 'hgb_max_depth': 2, 'hgb_min_samples_leaf': 2, 'svm_C': 9.836667442531127, 'svm_kernel': 'rbf', 'svm_gamma': 0.00881977578493193}. Best is trial 4 with value: 1.9321083527989558.\n",
      "[I 2024-03-08 12:24:52,635] Trial 6 finished with value: 1.931307276853666 and parameters: {'hgb_learning_rate': 0.02280601781756247, 'hgb_max_iter': 50, 'hgb_max_depth': 28, 'hgb_min_samples_leaf': 2, 'svm_C': 1.6833786298048685, 'svm_kernel': 'sigmoid', 'svm_gamma': 0.003194751708419497}. Best is trial 4 with value: 1.9321083527989558.\n",
      "[I 2024-03-08 12:24:52,666] Trial 2 finished with value: 1.9525110279939966 and parameters: {'hgb_learning_rate': 0.08461362911980046, 'hgb_max_iter': 52, 'hgb_max_depth': 24, 'hgb_min_samples_leaf': 6, 'svm_C': 7.344759914862007, 'svm_kernel': 'linear', 'svm_gamma': 0.008249605606658333}. Best is trial 2 with value: 1.9525110279939966.\n",
      "[I 2024-03-08 12:24:59,839] Trial 18 finished with value: 1.9022567794455876 and parameters: {'hgb_learning_rate': 0.005262922460066364, 'hgb_max_iter': 257, 'hgb_max_depth': 2, 'hgb_min_samples_leaf': 10, 'svm_C': 8.325201236162348, 'svm_kernel': 'rbf', 'svm_gamma': 0.006611988353914393}. Best is trial 2 with value: 1.9525110279939966.\n",
      "[I 2024-03-08 12:25:01,198] Trial 5 finished with value: 1.9304736161987628 and parameters: {'hgb_learning_rate': 0.015693018783035643, 'hgb_max_iter': 462, 'hgb_max_depth': 3, 'hgb_min_samples_leaf': 1, 'svm_C': 7.672052429679452, 'svm_kernel': 'sigmoid', 'svm_gamma': 0.007366931662802684}. Best is trial 2 with value: 1.9525110279939966.\n",
      "[I 2024-03-08 12:25:05,484] Trial 11 finished with value: 1.9512345891498761 and parameters: {'hgb_learning_rate': 0.01892684547622346, 'hgb_max_iter': 136, 'hgb_max_depth': 16, 'hgb_min_samples_leaf': 6, 'svm_C': 9.040475788648461, 'svm_kernel': 'linear', 'svm_gamma': 0.003241367019707805}. Best is trial 2 with value: 1.9525110279939966.\n",
      "[I 2024-03-08 12:25:06,097] Trial 9 finished with value: 1.9370580796589254 and parameters: {'hgb_learning_rate': 0.012340219413635847, 'hgb_max_iter': 141, 'hgb_max_depth': 28, 'hgb_min_samples_leaf': 4, 'svm_C': 5.434416469062738, 'svm_kernel': 'rbf', 'svm_gamma': 0.0013975395570075511}. Best is trial 2 with value: 1.9525110279939966.\n",
      "[I 2024-03-08 12:25:06,584] Trial 0 finished with value: 1.9340583020083342 and parameters: {'hgb_learning_rate': 0.0016739661601174684, 'hgb_max_iter': 172, 'hgb_max_depth': 7, 'hgb_min_samples_leaf': 6, 'svm_C': 1.7912067386586434, 'svm_kernel': 'linear', 'svm_gamma': 0.007120417205378686}. Best is trial 2 with value: 1.9525110279939966.\n",
      "[I 2024-03-08 12:25:07,418] Trial 13 finished with value: 1.9440935907937242 and parameters: {'hgb_learning_rate': 0.05645502418316997, 'hgb_max_iter': 195, 'hgb_max_depth': 6, 'hgb_min_samples_leaf': 2, 'svm_C': 6.57662492284823, 'svm_kernel': 'sigmoid', 'svm_gamma': 0.008599128754161073}. Best is trial 2 with value: 1.9525110279939966.\n",
      "[I 2024-03-08 12:25:07,748] Trial 8 finished with value: 1.9338461563775913 and parameters: {'hgb_learning_rate': 0.07572913302702701, 'hgb_max_iter': 154, 'hgb_max_depth': 24, 'hgb_min_samples_leaf': 10, 'svm_C': 0.7954986452094003, 'svm_kernel': 'sigmoid', 'svm_gamma': 0.004992108645678165}. Best is trial 2 with value: 1.9525110279939966.\n",
      "[I 2024-03-08 12:25:07,969] Trial 12 finished with value: 1.7629466993363936 and parameters: {'hgb_learning_rate': 0.015898160402231656, 'hgb_max_iter': 154, 'hgb_max_depth': 20, 'hgb_min_samples_leaf': 1, 'svm_C': 4.354363599059366, 'svm_kernel': 'poly', 'svm_gamma': 0.007029691341177706}. Best is trial 2 with value: 1.9525110279939966.\n",
      "[I 2024-03-08 12:25:10,542] Trial 1 finished with value: 1.9337960094868347 and parameters: {'hgb_learning_rate': 0.004724399588849181, 'hgb_max_iter': 185, 'hgb_max_depth': 27, 'hgb_min_samples_leaf': 10, 'svm_C': 0.6733307014776946, 'svm_kernel': 'rbf', 'svm_gamma': 0.0055190744436974075}. Best is trial 2 with value: 1.9525110279939966.\n",
      "[I 2024-03-08 12:25:14,921] Trial 7 finished with value: 1.943628081712698 and parameters: {'hgb_learning_rate': 0.015176718399406151, 'hgb_max_iter': 251, 'hgb_max_depth': 23, 'hgb_min_samples_leaf': 6, 'svm_C': 1.4497010899201388, 'svm_kernel': 'linear', 'svm_gamma': 0.0036868604377318158}. Best is trial 2 with value: 1.9525110279939966.\n",
      "[I 2024-03-08 12:25:17,949] Trial 16 finished with value: 1.761749881531411 and parameters: {'hgb_learning_rate': 0.007277371309231848, 'hgb_max_iter': 259, 'hgb_max_depth': 12, 'hgb_min_samples_leaf': 3, 'svm_C': 7.813999224976232, 'svm_kernel': 'poly', 'svm_gamma': 0.0017569156424456802}. Best is trial 2 with value: 1.9525110279939966.\n",
      "[I 2024-03-08 12:25:21,073] Trial 19 finished with value: 1.7580594542253292 and parameters: {'hgb_learning_rate': 0.0013928803781455225, 'hgb_max_iter': 256, 'hgb_max_depth': 29, 'hgb_min_samples_leaf': 4, 'svm_C': 3.7605292413117684, 'svm_kernel': 'poly', 'svm_gamma': 0.009126749013056807}. Best is trial 2 with value: 1.9525110279939966.\n",
      "[I 2024-03-08 12:25:21,811] Trial 15 finished with value: 1.9446447123883996 and parameters: {'hgb_learning_rate': 0.04111741273133119, 'hgb_max_iter': 380, 'hgb_max_depth': 28, 'hgb_min_samples_leaf': 6, 'svm_C': 9.812051660147564, 'svm_kernel': 'rbf', 'svm_gamma': 0.0037332607519206407}. Best is trial 2 with value: 1.9525110279939966.\n",
      "[I 2024-03-08 12:25:23,513] Trial 3 finished with value: 1.9467258293318865 and parameters: {'hgb_learning_rate': 0.0017993024938788562, 'hgb_max_iter': 415, 'hgb_max_depth': 16, 'hgb_min_samples_leaf': 6, 'svm_C': 2.9026521564125707, 'svm_kernel': 'linear', 'svm_gamma': 0.005569359816252348}. Best is trial 2 with value: 1.9525110279939966.\n",
      "[I 2024-03-08 12:25:24,954] Trial 10 finished with value: 1.9536587872241113 and parameters: {'hgb_learning_rate': 0.007380749580939124, 'hgb_max_iter': 464, 'hgb_max_depth': 18, 'hgb_min_samples_leaf': 8, 'svm_C': 9.290166683103118, 'svm_kernel': 'linear', 'svm_gamma': 0.0036481706038325747}. Best is trial 10 with value: 1.9536587872241113.\n",
      "[I 2024-03-08 12:25:25,186] Trial 14 finished with value: 1.9476859035977627 and parameters: {'hgb_learning_rate': 0.00289031986669825, 'hgb_max_iter': 483, 'hgb_max_depth': 9, 'hgb_min_samples_leaf': 10, 'svm_C': 2.6348767086102, 'svm_kernel': 'linear', 'svm_gamma': 0.006492419763299656}. Best is trial 10 with value: 1.9536587872241113.\n",
      "[I 2024-03-08 12:25:25,643] Trial 17 finished with value: 1.940343763626232 and parameters: {'hgb_learning_rate': 0.003620548087640153, 'hgb_max_iter': 434, 'hgb_max_depth': 25, 'hgb_min_samples_leaf': 10, 'svm_C': 1.2755339749901795, 'svm_kernel': 'linear', 'svm_gamma': 0.006973911795706106}. Best is trial 10 with value: 1.9536587872241113.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb_params = {\n",
    "    'learning_rate': optuna.distributions.FloatDistribution(0.001, 0.1),\n",
    "    'max_iter': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for HistGradientBoostingClassifier\n",
    "    hgb_hyperparams = {\n",
    "        'learning_rate': trial.suggest_float('hgb_learning_rate', 0.001, 0.1, log=True),\n",
    "        'max_iter': trial.suggest_int('hgb_max_iter', 50, 500),\n",
    "        'max_depth': trial.suggest_int('hgb_max_depth', 2, 32),\n",
    "        'min_samples_leaf': trial.suggest_int('hgb_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "\n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \n",
    "    \"\"\"\n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize and train HistGradientBoostingClassifier\n",
    "    hgb_classifier = HistGradientBoostingClassifier(**hgb_hyperparams)\n",
    "    hgb_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    hgb_predicted = hgb_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    hgb_precision = precision_score(y_validate_l1, hgb_predicted)\n",
    "    svm_precision = precision_score(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    hgb_recall = recall_score(y_validate_l1, hgb_predicted)\n",
    "    svm_recall = recall_score(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate weighted average of TPR and Precision (you can adjust weights based on preference)\n",
    "    weighted_score = (0.5 * (hgb_recall + svm_recall)) + (0.5 * (hgb_precision + svm_precision))\n",
    "    \n",
    "    return weighted_score\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T11:25:25.655948200Z",
     "start_time": "2024-03-08T11:24:41.037945100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S2 (RF+NBC) + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "hgb_params = {\n",
    "    'learning_rate': optuna.distributions.FloatDistribution(0.001, 0.1),\n",
    "    'max_iter': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "nbc_params = {\n",
    "    'var_smoothing': optuna.distributions.FloatDistribution(1e-10, 1e-1)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for Random Forest\n",
    "    rf_hyperparams = {\n",
    "        'n_estimators': trial.suggest_int('rf_n_estimators', 10, 70),\n",
    "        'max_depth': trial.suggest_int('rf_max_depth', 2, 32),\n",
    "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for GaussianNB\n",
    "    gnb_hyperparams = {\n",
    "        'var_smoothing': trial.suggest_float('gnb_var_smoothing', 1e-10, 1e-1, log=True)\n",
    "    }\n",
    "    \n",
    "    # Initialize the rf\n",
    "    rf_classifier = RandomForestClassifier(**rf_hyperparams)\n",
    "    \n",
    "    # Initialize the nbc\n",
    "    nbc_classifier = GaussianNB(**gnb_hyperparams)\n",
    "    \n",
    "    # Initialize and train voting classifier\n",
    "    voting_classifier = VotingClassifier(\n",
    "        estimators=[(\"rf\", rf_classifier), (\"nbc\", nbc_classifier)] ,\n",
    "        voting='soft'\n",
    "    )\n",
    "    voting_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    voting_predicted = voting_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    # Calculate confusion matrices for both classifiers\n",
    "    voting_cm = confusion_matrix(y_validate_l1, voting_predicted)\n",
    "    svm_cm = confusion_matrix(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate False Positive Rates for both classifiers\n",
    "    voting_fpr = voting_cm[0, 1] / np.sum(voting_cm[0, :])\n",
    "    svm_fpr = svm_cm[0, 1] / np.sum(svm_cm[0, :])\n",
    "    \n",
    "    # Calculate the average FPR\n",
    "    avg_fpr = (voting_fpr + svm_fpr) / 2\n",
    "    \n",
    "    return avg_fpr\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S2 (HGBC+NBC) + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "hgb_params = {\n",
    "    'learning_rate': optuna.distributions.FloatDistribution(0.001, 0.1),\n",
    "    'max_iter': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for HistGradientBoostingClassifier\n",
    "    hgb_hyperparams = {\n",
    "        'learning_rate': trial.suggest_float('hgb_learning_rate', 0.001, 0.1, log=True),\n",
    "        'max_iter': trial.suggest_int('hgb_max_iter', 50, 500),\n",
    "        'max_depth': trial.suggest_int('hgb_max_depth', 2, 32),\n",
    "        'min_samples_leaf': trial.suggest_int('hgb_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for GaussianNB\n",
    "    gnb_hyperparams = {\n",
    "        'var_smoothing': trial.suggest_float('gnb_var_smoothing', 1e-10, 1e-1, log=True)\n",
    "    }\n",
    "    \n",
    "    # Initialize the rf\n",
    "    hgb_classifier = HistGradientBoostingClassifier(**hgb_hyperparams)\n",
    "    \n",
    "    # Initialize the nbc\n",
    "    nbc_classifier = GaussianNB(**gnb_hyperparams)\n",
    "    \n",
    "    # Initialize and train voting classifier\n",
    "    voting_classifier = VotingClassifier(\n",
    "        estimators=[(\"hgbc\", hgb_classifier), (\"nbc\", nbc_classifier)] ,\n",
    "        voting='soft'\n",
    "    )\n",
    "    voting_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    voting_predicted = voting_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    # Calculate confusion matrices for both classifiers\n",
    "    voting_cm = confusion_matrix(y_validate_l1, voting_predicted)\n",
    "    svm_cm = confusion_matrix(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate False Positive Rates for both classifiers\n",
    "    voting_fpr = voting_cm[0, 1] / np.sum(voting_cm[0, :])\n",
    "    svm_fpr = svm_cm[0, 1] / np.sum(svm_cm[0, :])\n",
    "    \n",
    "    # Calculate the average FPR\n",
    "    avg_fpr = (voting_fpr + svm_fpr) / 2\n",
    "    \n",
    "    return avg_fpr\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S2 HGBC + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "hgb_params = {\n",
    "    'learning_rate': optuna.distributions.FloatDistribution(0.001, 0.1),\n",
    "    'max_iter': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for HistGradientBoostingClassifier\n",
    "    hgb_hyperparams = {\n",
    "        'learning_rate': trial.suggest_float('hgb_learning_rate', 0.001, 0.1, log=True),\n",
    "        'max_iter': trial.suggest_int('hgb_max_iter', 50, 500),\n",
    "        'max_depth': trial.suggest_int('hgb_max_depth', 2, 32),\n",
    "        'min_samples_leaf': trial.suggest_int('hgb_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for GaussianNB\n",
    "    gnb_hyperparams = {\n",
    "        'var_smoothing': trial.suggest_float('gnb_var_smoothing', 1e-10, 1e-1, log=True)\n",
    "    }\n",
    "    \n",
    "    # Initialize the rf\n",
    "    hgb_classifier = HistGradientBoostingClassifier(**hgb_hyperparams)\n",
    "    hgb_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    hgb_predicted = hgb_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    # Calculate confusion matrices for both classifiers\n",
    "    hgb_cm = confusion_matrix(y_validate_l1, hgb_predicted)\n",
    "    svm_cm = confusion_matrix(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate False Positive Rates for both classifiers\n",
    "    voting_fpr = hgb_cm[0, 1] / np.sum(hgb_cm[0, :])\n",
    "    svm_fpr = svm_cm[0, 1] / np.sum(svm_cm[0, :])\n",
    "    \n",
    "    # Calculate the average FPR\n",
    "    avg_fpr = (voting_fpr + svm_fpr) / 2\n",
    "    \n",
    "    return avg_fpr\n",
    "    \n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S2 RF + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "rf_params = {\n",
    "    'n_estimators': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_split': optuna.distributions.IntDistribution(2, 20),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "nbc_params = {\n",
    "    'var_smoothing': optuna.distributions.FloatDistribution(1e-10, 1e-1)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for Random Forest\n",
    "    rf_hyperparams = {\n",
    "        'n_estimators': trial.suggest_int('rf_n_estimators', 10, 70),\n",
    "        'max_depth': trial.suggest_int('rf_max_depth', 2, 32),\n",
    "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize and train HistGradientBoostingClassifier\n",
    "    rf_classifier = RandomForestClassifier(**rf_hyperparams)\n",
    "    rf_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    hgb_predicted = rf_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    # Calculate confusion matrices for both classifiers\n",
    "    hgb_cm = confusion_matrix(y_validate_l1, hgb_predicted)\n",
    "    svm_cm = confusion_matrix(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate False Positive Rates for both classifiers\n",
    "    rf_fpr = hgb_cm[0, 1] / np.sum(hgb_cm[0, :])\n",
    "    svm_fpr = svm_cm[0, 1] / np.sum(svm_cm[0, :])\n",
    "    \n",
    "    # Calculate the average FPR\n",
    "    avg_fpr = (rf_fpr + svm_fpr) / 2\n",
    "    \n",
    "    return avg_fpr\n",
    "    \n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S3 RF + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "import optuna\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_split': optuna.distributions.IntDistribution(2, 20),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for Random Forest\n",
    "    rf_hyperparams = {\n",
    "        'n_estimators': trial.suggest_int('rf_n_estimators', 10, 70),\n",
    "        'max_depth': trial.suggest_int('rf_max_depth', 2, 32),\n",
    "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize and train Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(**rf_hyperparams)\n",
    "    rf_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    rf_predicted = rf_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    # Calculate confusion matrices for both classifiers\n",
    "    rf_cm = confusion_matrix(y_validate_l1, rf_predicted)\n",
    "    svm_cm = confusion_matrix(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate False Positive Rates (FPR) and True Negative Rates (TNR) for both classifiers\n",
    "    rf_fpr = rf_cm[0, 1] / np.sum(rf_cm[0, :])\n",
    "    rf_tnr = rf_cm[0, 0] / np.sum(rf_cm[0, :])\n",
    "    \n",
    "    svm_fpr = svm_cm[0, 1] / np.sum(svm_cm[0, :])\n",
    "    svm_tnr = svm_cm[0, 0] / np.sum(svm_cm[0, :])\n",
    "    \n",
    "    # Calculate the average FPR and TNR\n",
    "    avg_fpr = (rf_fpr + svm_fpr) / 2\n",
    "    avg_tnr = (rf_tnr + svm_tnr) / 2\n",
    "    \n",
    "    # Aim to optimize both FPR and TNR\n",
    "    return avg_fpr + (1 - avg_tnr)\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S3 (RF+NBC) + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "import optuna\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_split': optuna.distributions.IntDistribution(2, 20),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "nbc_params = {\n",
    "    'var_smoothing': optuna.distributions.FloatDistribution(1e-10, 1e-1)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for Random Forest\n",
    "    rf_hyperparams = {\n",
    "        'n_estimators': trial.suggest_int('rf_n_estimators', 10, 70),\n",
    "        'max_depth': trial.suggest_int('rf_max_depth', 2, 32),\n",
    "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    # Define hyperparameters for GaussianNB\n",
    "    gnb_hyperparams = {\n",
    "        'var_smoothing': trial.suggest_float('gnb_var_smoothing', 1e-10, 1e-1, log=True)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    voting_classifier = VotingClassifier(\n",
    "        [(\"rf\", RandomForestClassifier(**rf_hyperparams)), (\"nbc\", GaussianNB(**gnb_hyperparams))],\n",
    "        voting='soft'\n",
    "    )\n",
    "    voting_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    voting_predicted = voting_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    # Calculate confusion matrices for both classifiers\n",
    "    voting_cm = confusion_matrix(y_validate_l1, voting_predicted)\n",
    "    svm_cm = confusion_matrix(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate False Positive Rates (FPR) and True Negative Rates (TNR) for both classifiers\n",
    "    rf_fpr = voting_cm[0, 1] / np.sum(voting_cm[0, :])\n",
    "    rf_tnr = voting_cm[0, 0] / np.sum(voting_cm[0, :])\n",
    "    \n",
    "    svm_fpr = svm_cm[0, 1] / np.sum(svm_cm[0, :])\n",
    "    svm_tnr = svm_cm[0, 0] / np.sum(svm_cm[0, :])\n",
    "    \n",
    "    # Calculate the average FPR and TNR\n",
    "    avg_fpr = (rf_fpr + svm_fpr) / 2\n",
    "    avg_tnr = (rf_tnr + svm_tnr) / 2\n",
    "    \n",
    "    # Aim to optimize both FPR and TNR\n",
    "    return avg_fpr + (1 - avg_tnr)\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S3 (HGBC+NBC) + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb_params = {\n",
    "    'learning_rate': optuna.distributions.FloatDistribution(0.001, 0.1),\n",
    "    'max_iter': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "nbc_params = {\n",
    "    'var_smoothing': optuna.distributions.FloatDistribution(1e-10, 1e-1)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for Random Forest\n",
    "    hgb_hyperparams = {\n",
    "        'learning_rate': trial.suggest_float('hgb_learning_rate', 0.001, 0.1, log=True),\n",
    "        'max_iter': trial.suggest_int('hgb_max_iter', 50, 500),\n",
    "        'max_depth': trial.suggest_int('hgb_max_depth', 2, 32),\n",
    "        'min_samples_leaf': trial.suggest_int('hgb_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    # Define hyperparameters for GaussianNB\n",
    "    gnb_hyperparams = {\n",
    "        'var_smoothing': trial.suggest_float('gnb_var_smoothing', 1e-10, 1e-1, log=True)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    voting_classifier = VotingClassifier(\n",
    "        [(\"hgbc\", HistGradientBoostingClassifier(**hgb_hyperparams)), (\"nbc\", GaussianNB(**gnb_hyperparams))],\n",
    "        voting='soft'\n",
    "    )\n",
    "    voting_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    voting_predicted = voting_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    # Calculate confusion matrices for both classifiers\n",
    "    voting_cm = confusion_matrix(y_validate_l1, voting_predicted)\n",
    "    svm_cm = confusion_matrix(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate False Positive Rates (FPR) and True Negative Rates (TNR) for both classifiers\n",
    "    rf_fpr = voting_cm[0, 1] / np.sum(voting_cm[0, :])\n",
    "    rf_tnr = voting_cm[0, 0] / np.sum(voting_cm[0, :])\n",
    "    \n",
    "    svm_fpr = svm_cm[0, 1] / np.sum(svm_cm[0, :])\n",
    "    svm_tnr = svm_cm[0, 0] / np.sum(svm_cm[0, :])\n",
    "    \n",
    "    # Calculate the average FPR and TNR\n",
    "    avg_fpr = (rf_fpr + svm_fpr) / 2\n",
    "    avg_tnr = (rf_tnr + svm_tnr) / 2\n",
    "    \n",
    "    # Aim to optimize both FPR and TNR\n",
    "    return avg_fpr + (1 - avg_tnr)\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S3 HGBC + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb_params = {\n",
    "    'learning_rate': optuna.distributions.FloatDistribution(0.001, 0.1),\n",
    "    'max_iter': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for Random Forest\n",
    "    hgb_hyperparams = {\n",
    "        'learning_rate': trial.suggest_float('hgb_learning_rate', 0.001, 0.1, log=True),\n",
    "        'max_iter': trial.suggest_int('hgb_max_iter', 50, 500),\n",
    "        'max_depth': trial.suggest_int('hgb_max_depth', 2, 32),\n",
    "        'min_samples_leaf': trial.suggest_int('hgb_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "   \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    hgb_classifier = HistGradientBoostingClassifier(**hgb_hyperparams)\n",
    "    hgb_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    hgb_predicted = hgb_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    # Calculate confusion matrices for both classifiers\n",
    "    hgb_cm = confusion_matrix(y_validate_l1, hgb_predicted)\n",
    "    svm_cm = confusion_matrix(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate False Positive Rates (FPR) and True Negative Rates (TNR) for both classifiers\n",
    "    rf_fpr = hgb_cm[0, 1] / np.sum(hgb_cm[0, :])\n",
    "    rf_tnr = hgb_cm[0, 0] / np.sum(hgb_cm[0, :])\n",
    "    \n",
    "    svm_fpr = svm_cm[0, 1] / np.sum(svm_cm[0, :])\n",
    "    svm_tnr = svm_cm[0, 0] / np.sum(svm_cm[0, :])\n",
    "    \n",
    "    # Calculate the average FPR and TNR\n",
    "    avg_fpr = (rf_fpr + svm_fpr) / 2\n",
    "    avg_tnr = (rf_tnr + svm_tnr) / 2\n",
    "    \n",
    "    # Aim to optimize both FPR and TNR\n",
    "    return avg_fpr + (1 - avg_tnr)\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S4 HGBC + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb_params = {\n",
    "    'learning_rate': optuna.distributions.FloatDistribution(0.001, 0.1),\n",
    "    'max_iter': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for Random Forest\n",
    "    hgb_hyperparams = {\n",
    "        'learning_rate': trial.suggest_float('hgb_learning_rate', 0.001, 0.1, log=True),\n",
    "        'max_iter': trial.suggest_int('hgb_max_iter', 50, 500),\n",
    "        'max_depth': trial.suggest_int('hgb_max_depth', 2, 32),\n",
    "        'min_samples_leaf': trial.suggest_int('hgb_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    hgb_classifier = HistGradientBoostingClassifier(**hgb_hyperparams)\n",
    "    hgb_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    hgb_predicted = hgb_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    # Calculate confusion matrices for both classifiers\n",
    "    hgb_cm = confusion_matrix(y_validate_l1, hgb_predicted)\n",
    "    svm_cm = confusion_matrix(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate Precision and False Negative Rate (FNR) for both classifiers\n",
    "    hgb_precision = hgb_cm[1, 1] / np.sum(hgb_cm[:, 1])\n",
    "    hgb_fnr = hgb_cm[1, 0] / np.sum(hgb_cm[1, :])\n",
    "    \n",
    "    svm_precision = svm_cm[1, 1] / np.sum(svm_cm[:, 1])\n",
    "    svm_fnr = svm_cm[1, 0] / np.sum(svm_cm[1, :])\n",
    "    \n",
    "    # Calculate the average Precision and FNR\n",
    "    avg_precision = (hgb_precision + svm_precision) / 2\n",
    "    avg_fnr = (hgb_fnr + svm_fnr) / 2\n",
    "    \n",
    "    # Aim to optimize both Precision and FNR\n",
    "    return 1 - (avg_precision + avg_fnr)  # Minimize the sum of Precision and FNR\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S4 (HGBC+NBC) + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb_params = {\n",
    "    'learning_rate': optuna.distributions.FloatDistribution(0.001, 0.1),\n",
    "    'max_iter': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "nbc_params = {\n",
    "    'var_smoothing': optuna.distributions.FloatDistribution(1e-10, 1e-1)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for Random Forest\n",
    "    hgb_hyperparams = {\n",
    "        'learning_rate': trial.suggest_float('hgb_learning_rate', 0.001, 0.1, log=True),\n",
    "        'max_iter': trial.suggest_int('hgb_max_iter', 50, 500),\n",
    "        'max_depth': trial.suggest_int('hgb_max_depth', 2, 32),\n",
    "        'min_samples_leaf': trial.suggest_int('hgb_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    # Define hyperparameters for GaussianNB\n",
    "    gnb_hyperparams = {\n",
    "        'var_smoothing': trial.suggest_float('gnb_var_smoothing', 1e-10, 1e-1, log=True)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    voting_classifier = VotingClassifier(\n",
    "        [(\"hgbc\", HistGradientBoostingClassifier(**hgb_hyperparams)), (\"nbc\", GaussianNB(**gnb_hyperparams))],\n",
    "        voting='soft'\n",
    "    )\n",
    "    voting_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    hgb_classifier = HistGradientBoostingClassifier(**hgb_hyperparams)\n",
    "    hgb_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    hgb_predicted = hgb_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    # Calculate confusion matrices for both classifiers\n",
    "    hgb_cm = confusion_matrix(y_validate_l1, hgb_predicted)\n",
    "    svm_cm = confusion_matrix(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate Precision and False Negative Rate (FNR) for both classifiers\n",
    "    hgb_precision = hgb_cm[1, 1] / np.sum(hgb_cm[:, 1])\n",
    "    hgb_fnr = hgb_cm[1, 0] / np.sum(hgb_cm[1, :])\n",
    "    \n",
    "    svm_precision = svm_cm[1, 1] / np.sum(svm_cm[:, 1])\n",
    "    svm_fnr = svm_cm[1, 0] / np.sum(svm_cm[1, :])\n",
    "    \n",
    "    # Calculate the average Precision and FNR\n",
    "    avg_precision = (hgb_precision + svm_precision) / 2\n",
    "    avg_fnr = (hgb_fnr + svm_fnr) / 2\n",
    "    \n",
    "    # Aim to optimize both Precision and FNR\n",
    "    return 1 - (avg_precision + avg_fnr)  # Minimize the sum of Precision and FNR\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S4 RF + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "import optuna\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_split': optuna.distributions.IntDistribution(2, 20),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for Random Forest\n",
    "    rf_hyperparams = {\n",
    "        'n_estimators': trial.suggest_int('rf_n_estimators', 10, 70),\n",
    "        'max_depth': trial.suggest_int('rf_max_depth', 2, 32),\n",
    "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize and train Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(**rf_hyperparams)\n",
    "    rf_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    rf_predicted = rf_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    # Calculate confusion matrices for both classifiers\n",
    "    rf_cm = confusion_matrix(y_validate_l1, rf_predicted)\n",
    "    svm_cm = confusion_matrix(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate Precision and False Negative Rate (FNR) for both classifiers\n",
    "    rf_precision = rf_cm[1, 1] / np.sum(rf_cm[:, 1])\n",
    "    rf_fnr = rf_cm[1, 0] / np.sum(rf_cm[1, :])\n",
    "    \n",
    "    svm_precision = svm_cm[1, 1] / np.sum(svm_cm[:, 1])\n",
    "    svm_fnr = svm_cm[1, 0] / np.sum(svm_cm[1, :])\n",
    "    \n",
    "    # Calculate the average Precision and FNR\n",
    "    avg_precision = (rf_precision + svm_precision) / 2\n",
    "    avg_fnr = (rf_fnr + svm_fnr) / 2\n",
    "    \n",
    "    # Aim to optimize both Precision and FNR\n",
    "    return 1 - (avg_precision + avg_fnr)  # Minimize the sum of Precision and FNR\n",
    "    \n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S4 (RF+NBC) + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "import optuna\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_split': optuna.distributions.IntDistribution(2, 20),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "nbc_params = {\n",
    "    'var_smoothing': optuna.distributions.FloatDistribution(1e-10, 1e-1)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for Random Forest\n",
    "    rf_hyperparams = {\n",
    "        'n_estimators': trial.suggest_int('rf_n_estimators', 10, 70),\n",
    "        'max_depth': trial.suggest_int('rf_max_depth', 2, 32),\n",
    "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    # Define hyperparameters for GaussianNB\n",
    "    gnb_hyperparams = {\n",
    "        'var_smoothing': trial.suggest_float('gnb_var_smoothing', 1e-10, 1e-1, log=True)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    voting_classifier = VotingClassifier(\n",
    "        [(\"rf\", RandomForestClassifier(**rf_hyperparams)), (\"nbc\", GaussianNB(**gnb_hyperparams))],\n",
    "        voting='soft'\n",
    "    )\n",
    "    voting_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    voting_predicted = voting_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    # Calculate confusion matrices for both classifiers\n",
    "    voting_cm = confusion_matrix(y_validate_l1, voting_predicted)\n",
    "    svm_cm = confusion_matrix(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate Precision and False Negative Rate (FNR) for both classifiers\n",
    "    voting_precision = voting_cm[1, 1] / np.sum(voting_cm[:, 1])\n",
    "    voting_fnr = voting_cm[1, 0] / np.sum(voting_cm[1, :])\n",
    "    \n",
    "    svm_precision = svm_cm[1, 1] / np.sum(svm_cm[:, 1])\n",
    "    svm_fnr = svm_cm[1, 0] / np.sum(svm_cm[1, :])\n",
    "    \n",
    "    # Calculate the average Precision and FNR\n",
    "    avg_precision = (voting_precision + svm_precision) / 2\n",
    "    avg_fnr = (voting_fnr + svm_fnr) / 2\n",
    "    \n",
    "    # Aim to optimize both Precision and FNR\n",
    "    return 1 - (avg_precision + avg_fnr)  # Minimize the sum of Precision and FNR\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:25:25.671378900Z",
     "start_time": "2024-03-08T11:25:25.649739100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning_time:  0:00:44.597607\n"
     ]
    }
   ],
   "source": [
    "print('tuning_time: ', tuning_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Get the best hyperparameters for RF + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "best_params1 = {\n",
    "    'n_estimators': study.best_trial.params['rf_n_estimators'],\n",
    "    'max_depth': study.best_trial.params['rf_max_depth'],\n",
    "    'min_samples_split': study.best_trial.params['rf_min_samples_split'],\n",
    "    'min_samples_leaf': study.best_trial.params['rf_min_samples_leaf']\n",
    "}\n",
    "\n",
    "best_params2 = {\n",
    "    'C': study.best_trial.params['svm_C'],\n",
    "    'kernel': study.best_trial.params['svm_kernel'],\n",
    "    'gamma': study.best_trial.params['svm_gamma']\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Get the best hyperparameters for HGBC + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "outputs": [],
   "source": [
    "best_params1 = {\n",
    "    'learning_rate': study.best_trial.params['hgb_learning_rate'],\n",
    "    'max_depth': study.best_trial.params['hgb_max_depth'],\n",
    "    'max_iter': study.best_trial.params['hgb_max_iter'],\n",
    "    'min_samples_leaf': study.best_trial.params['hgb_min_samples_leaf']\n",
    "}\n",
    "\n",
    "best_params2 = {\n",
    "    'C': study.best_trial.params['svm_C'],\n",
    "    'kernel': study.best_trial.params['svm_kernel'],\n",
    "    'gamma': study.best_trial.params['svm_gamma']\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T11:25:25.688673Z",
     "start_time": "2024-03-08T11:25:25.655948200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Get the best hyperparameters for (RF+NBC) + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "best_params1 = {\n",
    "    'n_estimators': study.best_trial.params['rf_n_estimators'],\n",
    "    'max_depth': study.best_trial.params['rf_max_depth'],\n",
    "    'min_samples_split': study.best_trial.params['rf_min_samples_split'],\n",
    "    'min_samples_leaf': study.best_trial.params['rf_min_samples_leaf']\n",
    "}\n",
    "\n",
    "best_params_nbc = {\n",
    "    'var_smoothing': study.best_trial.params['gnb_var_smoothing']\n",
    "}\n",
    "\n",
    "best_params2 = {\n",
    "    'C': study.best_trial.params['svm_C'],\n",
    "    'kernel': study.best_trial.params['svm_kernel'],\n",
    "    'gamma': study.best_trial.params['svm_gamma']\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print(best_params_nbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Get the best hyperparameters for (HGBC+NBC) + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "best_params1 = {\n",
    "    'learning_rate': study.best_trial.params['hgb_learning_rate'],\n",
    "    'max_depth': study.best_trial.params['hgb_max_depth'],\n",
    "    'max_iter': study.best_trial.params['hgb_max_iter'],\n",
    "    'min_samples_leaf': study.best_trial.params['hgb_min_samples_leaf']\n",
    "}\n",
    "\n",
    "best_params_nbc = {\n",
    "    'var_smoothing': study.best_trial.params['gnb_var_smoothing']\n",
    "}\n",
    "\n",
    "# Get the best hyperparameters for SVM\n",
    "best_params2 = {\n",
    "    'C': study.best_trial.params['svm_C'],\n",
    "    'kernel': study.best_trial.params['svm_kernel'],\n",
    "    'gamma': study.best_trial.params['svm_gamma']\n",
    "}\n",
    "\n",
    "print(best_params_nbc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:25:25.692782800Z",
     "start_time": "2024-03-08T11:25:25.662977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.007380749580939124, 'max_depth': 18, 'max_iter': 464, 'min_samples_leaf': 8} {'C': 9.290166683103118, 'kernel': 'linear', 'gamma': 0.0036481706038325747}\n"
     ]
    }
   ],
   "source": [
    "print(best_params1, best_params2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train RF + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "best_classifier1 = RandomForestClassifier(**best_params1)\n",
    "best_classifier1.fit(X_train_dos_probe, y_train_l1)\n",
    "\n",
    "best_classifier2 = SVC(**best_params2)\n",
    "best_classifier2.fit(X_train_r2l_u2r, y_train_l2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train HGBC + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "outputs": [
    {
     "data": {
      "text/plain": "SVC(C=9.290166683103118, gamma=0.0036481706038325747, kernel='linear')",
      "text/html": "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=9.290166683103118, gamma=0.0036481706038325747, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=9.290166683103118, gamma=0.0036481706038325747, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_classifier1 = HistGradientBoostingClassifier(**best_params1)\n",
    "best_classifier1.fit(X_train_dos_probe, y_train_l1)\n",
    "\n",
    "best_classifier2 = SVC(**best_params2)\n",
    "best_classifier2.fit(X_train_r2l_u2r, y_train_l2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T11:25:30.589336500Z",
     "start_time": "2024-03-08T11:25:25.668378900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train (RF+NBC) + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "best_classifier1 = VotingClassifier(\n",
    "    [(\"rf\", RandomForestClassifier(**best_params1)), (\"nbc\", GaussianNB(**best_params_nbc))],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "best_classifier2 = SVC(**best_params2)\n",
    "\n",
    "best_classifier1.fit(X_train_dos_probe, y_train_l1)\n",
    "best_classifier2.fit(X_train_r2l_u2r, y_train_l2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train (HGBC+NBC) + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "best_classifier1 = VotingClassifier(\n",
    "    [(\"hgbc\", HistGradientBoostingClassifier(**best_params1)), (\"nbc\", GaussianNB(**best_params_nbc))],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "best_classifier2 = SVC(**best_params2)\n",
    "\n",
    "best_classifier1.fit(X_train_dos_probe, y_train_l1)\n",
    "best_classifier2.fit(X_train_r2l_u2r, y_train_l2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "outputs": [],
   "source": [
    "classifier1 = best_classifier1\n",
    "classifier2 = best_classifier2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T11:25:30.606453400Z",
     "start_time": "2024-03-08T11:25:30.585228100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T11:27:29.834457400Z",
     "start_time": "2024-03-08T11:25:30.590391100Z"
    }
   },
   "outputs": [],
   "source": [
    "# the results may vary\n",
    "accuracy, f_score, precision, recall, clf_time, tnr, fpr, fnr, result = test_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.8251863023420866\n",
      "F1 Score =  0.8273989401305128\n",
      "Precision =  0.9446\n",
      "Recall =  0.7360710667809554\n",
      "True Negative Rate (TNR) = 0.9429512923488828\n",
      "False Positive Rate (FPR) = 0.05704870765111729\n",
      "False Negative Rate (FNR) = 0.26392893321904465\n",
      "Classification time =  0:01:59.202775\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy = ', accuracy)\n",
    "print('F1 Score = ', f_score)\n",
    "print('Precision = ', precision)\n",
    "print('Recall = ', recall)\n",
    "print('True Negative Rate (TNR) =', tnr)\n",
    "print('False Positive Rate (FPR) =', fpr)\n",
    "\n",
    "print('False Negative Rate (FNR) =', fnr)\n",
    "\n",
    "print('Classification time = ', clf_time)"
   ],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:27:29.861329800Z",
     "start_time": "2024-03-08T11:27:29.836455600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC graph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test_real, result)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.savefig('static_roc_curve-hgbc.png')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T11:27:30.077056600Z",
     "start_time": "2024-03-08T11:27:29.844319500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Export the test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "if True:\n",
    "    column_names = [f'PC{i}' for i in range(1, X_test_layer1.shape[1] + 1)]\n",
    "    X1_test = pd.DataFrame(data=X_test_layer1, columns=column_names)\n",
    "    X1_test.to_csv('EvalResources/AdditionalSets/x_test_l1_pca.txt', index=False)\n",
    "    \n",
    "    column_names = [f'PC{i}' for i in range(1, X_test_layer2.shape[1] + 1)]\n",
    "    X2_test = pd.DataFrame(data=X_test_layer2, columns=column_names)\n",
    "    X2_test.to_csv('EvalResources/AdditionalSets/x_test_l2_pca.txt', index=False)\n",
    "    \n",
    "    np.save('EvalResources/AdditionalSets/y_test', y_test_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate seen and unseen attack categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:27:30.195082400Z",
     "start_time": "2024-03-08T11:27:30.074953300Z"
    }
   },
   "outputs": [],
   "source": [
    "# load testset\n",
    "df_test = pd.read_csv('EvalResources/KDDTest+.txt', sep=\",\", header=None, skipinitialspace = True)\n",
    "df_test = df_test[df_test.columns[:-1]]\n",
    "df_test.columns = titles.to_list()\n",
    "y_test = df_test['label']\n",
    "df_test = df_test.drop(['num_outbound_cmds'],axis=1)\n",
    "\n",
    "df_test_original = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "if EXPORT_DATASETS:\n",
    "    df_test_original.to_csv('EvalResources/ProcessedDatasets/x_test_full.txt', index=False)\n",
    "    np.save('EvalResources/ProcessedDatasets/y_test_full', y_test)\n",
    "    \n",
    "#df_test_original"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:27:30.309553700Z",
     "start_time": "2024-03-08T11:27:30.148853700Z"
    }
   },
   "outputs": [],
   "source": [
    "new_attack = []\n",
    "for i in df_test_original['label'].value_counts().index.tolist()[1:]:\n",
    "    if i not in df_train_original['label'].value_counts().index.tolist()[1:]:\n",
    "        new_attack.append(i)\n",
    "        \n",
    "new_attack.sort()\n",
    "#new_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:27:30.409946100Z",
     "start_time": "2024-03-08T11:27:30.310621300Z"
    }
   },
   "outputs": [],
   "source": [
    "index_of_new_attacks = []\n",
    "\n",
    "for i in range(len(df_test_original)):\n",
    "    if df_test_original['label'][i] in new_attack:\n",
    "        index_of_new_attacks.append(df_test_original.index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:27:30.412775600Z",
     "start_time": "2024-03-08T11:27:30.404189500Z"
    }
   },
   "outputs": [],
   "source": [
    "#len(index_of_new_attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:27:30.443288300Z",
     "start_time": "2024-03-08T11:27:30.409946100Z"
    }
   },
   "outputs": [],
   "source": [
    "new_attack.append('normal')\n",
    "#new_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:27:30.534865Z",
     "start_time": "2024-03-08T11:27:30.464206100Z"
    }
   },
   "outputs": [],
   "source": [
    "index_of_old_attacks = []\n",
    "\n",
    "for i in range(len(df_test_original)):\n",
    "    if df_test_original['label'][i] not in new_attack:\n",
    "        index_of_old_attacks.append(df_test_original.index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:27:30.551881300Z",
     "start_time": "2024-03-08T11:27:30.517631300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new attacks in the test set:  3750\n",
      "Number of new attacks detected by the classifiers:  1875\n",
      "Proportion of new attacks detected:  0.5\n"
     ]
    }
   ],
   "source": [
    "print('Number of new attacks in the test set: ', result[index_of_new_attacks].shape[0])\n",
    "print('Number of new attacks detected by the classifiers: ', result[index_of_new_attacks].sum())\n",
    "print('Proportion of new attacks detected: ', result[index_of_new_attacks].sum()/result[index_of_new_attacks].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:27:30.556851300Z",
     "start_time": "2024-03-08T11:27:30.523816100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of old attacks in the test set:  9083\n",
      "Number of old attacks detected by the classifiers:  7571\n",
      "Proportion of old attacks detected:  0.8335351756027745\n"
     ]
    }
   ],
   "source": [
    "print('Number of old attacks in the test set: ', result[index_of_old_attacks].shape[0])\n",
    "print('Number of old attacks detected by the classifiers: ', result[index_of_old_attacks].sum())\n",
    "print('Proportion of old attacks detected: ', result[index_of_old_attacks].sum()/result[index_of_old_attacks].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate single attack types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-08T11:27:30.718371400Z",
     "start_time": "2024-03-08T11:27:30.534865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio DOS of detection:  0.803083109919571\n",
      "Ratio PROBE of detection:  0.9508467575382074\n",
      "Ratio U2R of detection:  0.3809358752166378\n",
      "Ratio R2L of detection:  0.8059701492537313\n",
      "New attacks detected:  0.5\n",
      "Old attacks detected:  0.8335351756027745\n"
     ]
    }
   ],
   "source": [
    "# load test set\n",
    "df_test = pd.read_csv('EvalResources/KDDTest+.txt', sep=\",\", header=None, skipinitialspace = True)\n",
    "df_test = df_test[df_test.columns[:-1]]\n",
    "df_test.columns = titles.to_list()\n",
    "y_test = df_test['label']\n",
    "df_test = df_test.drop(['num_outbound_cmds'],axis=1)\n",
    "df_test_original = df_test\n",
    "df = df_test_original\n",
    "\n",
    "dos_index = df.index[(df['label'].isin(dos_attacks))].tolist()\n",
    "probe_index = df.index[(df['label'].isin(probe_attacks))].tolist()\n",
    "r2l_index = df.index[(df['label'].isin(r2l_attacks))].tolist()\n",
    "u2r_index = df.index[(df['label'].isin(u2r_attacks))].tolist()\n",
    "\n",
    "print(\"Ratio DOS of detection: \", result[dos_index].sum()/result[dos_index].shape[0])\n",
    "\n",
    "print(\"Ratio PROBE of detection: \", result[probe_index].sum()/result[probe_index].shape[0])\n",
    "\n",
    "print(\"Ratio U2R of detection: \", result[r2l_index].sum()/result[r2l_index].shape[0])\n",
    "\n",
    "print(\"Ratio R2L of detection: \", result[u2r_index].sum()/result[u2r_index].shape[0])\n",
    "\n",
    "print('New attacks detected: ', result[index_of_new_attacks].sum()/result[index_of_new_attacks].shape[0])\n",
    "\n",
    "print('Old attacks detected: ', result[index_of_old_attacks].sum()/result[index_of_old_attacks].shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
