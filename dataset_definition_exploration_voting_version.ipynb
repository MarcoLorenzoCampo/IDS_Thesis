{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:13.148680900Z",
     "start_time": "2024-03-06T16:13:11.921855400Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.under_sampling import RandomUnderSampler as under_sam\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.metrics import matthews_corrcoef, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Main implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:13.788124400Z",
     "start_time": "2024-03-06T16:13:13.151682600Z"
    }
   },
   "outputs": [],
   "source": [
    "# loading the train set\n",
    "df_train = pd.read_csv('EvalResources/KDDTrain+.txt', sep=\",\", header=None, skipinitialspace = True)\n",
    "df_train = df_train[df_train.columns[:-1]]  # tags column\n",
    "titles = pd.read_csv('EvalResources/Field Names.csv', header=None, skipinitialspace = True)\n",
    "label = pd.Series(['label'], index=[41])\n",
    "titles = pd.concat([titles[0], label])\n",
    "df_train.columns = titles.to_list()\n",
    "df_train = df_train.drop(['num_outbound_cmds'],axis=1)\n",
    "df_train_original = df_train\n",
    "\n",
    "# df_train_original.to_csv('KB Process/NSL-KDD Original Datasets/KDDTrain+_with_labels.txt', index=False)\n",
    "\n",
    "#df_train_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:13.879570800Z",
     "start_time": "2024-03-06T16:13:13.705046900Z"
    }
   },
   "outputs": [],
   "source": [
    "# load test set\n",
    "df_test = pd.read_csv('EvalResources/KDDTest+.txt', sep=\",\", header=None, skipinitialspace = True)\n",
    "df_test_ = df_test.sort_index(axis=1)\n",
    "df_test = df_test[df_test.columns[:-1]]\n",
    "df_test.columns = titles.to_list()\n",
    "df_test = df_test.drop(['num_outbound_cmds'],axis=1)\n",
    "df_test_original = df_test\n",
    "\n",
    "# df_test_original.to_csv('KB Process/NSL-KDD Original Datasets/KDDTest+.txt', index=False)\n",
    "\n",
    "#df_test_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Execution Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:13.883831100Z",
     "start_time": "2024-03-06T16:13:13.799199700Z"
    }
   },
   "outputs": [],
   "source": [
    "EXPORT_MODELS = 0\n",
    "EXPORT_DATASETS = 0\n",
    "EXPORT_PCA = 0\n",
    "EXPORT_ENCODERS = 0\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:13.950066600Z",
     "start_time": "2024-03-06T16:13:13.808964400Z"
    }
   },
   "outputs": [],
   "source": [
    "# list of single attacks \n",
    "dos_attacks = ['back', 'land', 'neptune', 'pod', 'smurf', 'teardrop', 'worm', 'apache2', 'mailbomb', 'processtable', 'udpstorm']\n",
    "probe_attacks = ['ipsweep', 'mscan', 'nmap', 'portsweep', 'saint', 'satan']\n",
    "r2l_attacks = ['guess_passwd', 'ftp_write', 'imap', 'phf', 'multihop', 'warezmaster',\n",
    "                'snmpguess', 'spy', 'warezclient', 'httptunnel', 'named', 'sendmail', 'snmpgetattack', 'xlock', 'xsnoop']\n",
    "u2r_attacks = ['buffer_overflow', 'loadmodule', 'perl', 'ps', 'rootkit', 'sqlattack', 'xterm'] \n",
    "\n",
    "# list of attack classes split according to detection layer\n",
    "dos_probe_list = ['back', 'land', 'neptune', 'pod', 'smurf', 'teardrop', 'ipsweep', 'nmap', 'portsweep', 'satan']\n",
    "dos_probe_test = ['apache2', 'mailbomb', 'processtable', 'udpstorm', 'mscan', 'saint']\n",
    "u2r_r2l_list = ['guess_passwd', 'ftp_write', 'imap', 'phf', 'multihop', 'warezmaster',\n",
    "                'snmpguess', 'spy', 'warezclient', 'buffer_overflow', 'loadmodule', 'rootkit', 'perl']\n",
    "u2r_r2l_test = ['httptunnel', 'named', 'sendmail', 'snmpgetattack', 'xlock', 'xsnoop', 'ps', 'xterm', 'sqlattack']\n",
    "normal_list = ['normal']\n",
    "categorical_features = ['protocol_type', 'service', 'flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:13.981607900Z",
     "start_time": "2024-03-06T16:13:13.816234100Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the features obtained with ICFS for both layer 1 and layer 2\n",
    "with open('KBProcess/AWS Downloads/MinimalFeatures/NSL_features_l1.txt', 'r') as f:\n",
    "    common_features_l1 = f.read().split(',')\n",
    "\n",
    "with open('KBProcess/AWS Downloads/MinimalFeatures/NSL_features_l2.txt', 'r') as f:\n",
    "    common_features_l2 = f.read().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:14.011516200Z",
     "start_time": "2024-03-06T16:13:13.820971500Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_and_validate = copy.deepcopy(df_train_original)\n",
    "df_test = copy.deepcopy(df_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:14.029328900Z",
     "start_time": "2024-03-06T16:13:13.871435300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save all the targets for the dataset\n",
    "\n",
    "y_test_l1 = [1 if x in (dos_attacks+probe_attacks) else 0 for x in df_test['label']]\n",
    "y_test_l2 = [1 if x in (u2r_attacks+r2l_attacks) else 0 for x in df_test['label']]\n",
    "\n",
    "if EXPORT_DATASETS:\n",
    "    np.save(\"EvalResources/AdditionalSets/l1_full_test_targets.npy\", y_test_l1)\n",
    "    np.save(\"EvalResources/AdditionalSets/l2_full_test_targets.npy\", y_test_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:14.081534600Z",
     "start_time": "2024-03-06T16:13:13.884899800Z"
    }
   },
   "outputs": [],
   "source": [
    "# add an additional column to th dataframe to perform splitting\n",
    "\n",
    "attacks = ['dos' if x in dos_attacks else\n",
    "           'probe' if x in probe_attacks else\n",
    "           'u2r' if x in u2r_attacks else\n",
    "           'r2l' if x in r2l_attacks else\n",
    "           'normal' for x in df_train_and_validate['label']]\n",
    "\n",
    "# add the column to the dataframe\n",
    "df_train_and_validate['attacks'] = attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOS PROBE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:14.292958200Z",
     "start_time": "2024-03-06T16:13:14.049403400Z"
    }
   },
   "outputs": [],
   "source": [
    "# split in test and validation set for BOTH layers\n",
    "df_train_original, df_val_original = train_test_split(df_train_and_validate, test_size=0.3, stratify=df_train_and_validate['attacks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame and 'column_name' is the specific column you want to plot\n",
    "plt.hist(df_val_original['attacks'], bins=10)  # Adjust the number of bins as needed\n",
    "plt.xlabel('Values')  # Set x-axis label\n",
    "plt.ylabel('Frequency')  # Set y-axis label\n",
    "plt.title('Histogram of Column')  # Set title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame and 'column_name' is the specific column you want to plot\n",
    "plt.hist(df_train_original['attacks'], bins=10)  # Adjust the number of bins as needed\n",
    "plt.xlabel('Values')  # Set x-axis label\n",
    "plt.ylabel('Frequency')  # Set y-axis label\n",
    "plt.title('Histogram of Column')  # Set title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:14.480310400Z",
     "start_time": "2024-03-06T16:13:14.249448600Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataframes specifically for layer 1\n",
    "df_train = copy.deepcopy(df_train_original)\n",
    "df_val = copy.deepcopy(df_val_original)\n",
    "df_test = copy.deepcopy(df_test_original)\n",
    "\n",
    "# target variables for all layers\n",
    "y_train_full = np.array([1 if x not in normal_list else 0 for x in df_train['label']])\n",
    "y_test_full = np.array([1 if x not in normal_list else 0 for x in df_test['label']])\n",
    "\n",
    "# set the target variables accordingly\n",
    "y_train_l1 = np.array([1 if x in (dos_attacks+probe_attacks) else 0 for x in df_train['label']])\n",
    "y_validate_l1 = np.array([1 if x in (dos_attacks+probe_attacks) else 0 for x in df_val['label']])\n",
    "y_test = np.array([1 if x in (dos_attacks+probe_attacks) else 0 for x in df_test ['label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:14.526101Z",
     "start_time": "2024-03-06T16:13:14.356961Z"
    }
   },
   "outputs": [],
   "source": [
    "# this dataframe contains the whole train set \n",
    "df_train = df_train.drop(['label'],axis=1)\n",
    "df_train = df_train.reset_index().drop(['index'], axis=1)\n",
    "#df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:14.600981200Z",
     "start_time": "2024-03-06T16:13:14.479197600Z"
    }
   },
   "outputs": [],
   "source": [
    "# this dataframe contains the whole validation set\n",
    "df_val = df_val.drop(['label'],axis=1)\n",
    "df_val = df_val.reset_index().drop(['index'], axis=1)\n",
    "#df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:14.728942500Z",
     "start_time": "2024-03-06T16:13:14.580046700Z"
    }
   },
   "outputs": [],
   "source": [
    "# this dataframe contains the whole test set\n",
    "df_test = df_test.drop(['label'],axis=1)\n",
    "df_test = df_test.reset_index().drop(['index'], axis=1)\n",
    "#df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Using features obtained with a random forest on numerical features only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# List of feature names\n",
    "feature_names_l1 = ['src_bytes', 'logged_in', 'count', 'srv_count', 'srv_serror_rate',\n",
    "       'same_srv_rate', 'diff_srv_rate', 'dst_host_srv_count',\n",
    "       'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
    "       'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n",
    "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
    "       'dst_host_srv_rerror_rate']\n",
    "\n",
    "# Selecting features using loc\n",
    "X_train = df_train.loc[:, feature_names_l1]\n",
    "X_validate = df_val.loc[:, feature_names_l1]\n",
    "X_test = df_test.loc[:, feature_names_l1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:14.867562100Z",
     "start_time": "2024-03-06T16:13:14.702508900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using the features extracted by using the ICFS algorithm\n",
    "X_train = df_train[common_features_l1]\n",
    "X_validate = df_val[common_features_l1]\n",
    "X_test = df_test[common_features_l1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:14.943253Z",
     "start_time": "2024-03-06T16:13:14.776618400Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2 one-hot encoders, one for the features of layer1 and one for the features of layer2\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "ohe2 = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:15.086368300Z",
     "start_time": "2024-03-06T16:13:14.923617800Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler1 = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:15.126270500Z",
     "start_time": "2024-03-06T16:13:15.074610Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler2 = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:15.269443400Z",
     "start_time": "2024-03-06T16:13:15.125266200Z"
    }
   },
   "outputs": [],
   "source": [
    "# scaling the train set for layer1\n",
    "df_minmax = scaler1.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(df_minmax, columns=X_train.columns)\n",
    "\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:15.332288500Z",
     "start_time": "2024-03-06T16:13:15.243535200Z"
    }
   },
   "outputs": [],
   "source": [
    "# scaling the validation set for layer1\n",
    "df_minmax_val = scaler1.transform(X_validate)\n",
    "X_validate = pd.DataFrame(df_minmax_val, columns=X_validate.columns)\n",
    "\n",
    "#X_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:15.466591100Z",
     "start_time": "2024-03-06T16:13:15.330187800Z"
    }
   },
   "outputs": [],
   "source": [
    "# scaling the test set for layer1\n",
    "df_minmax_test = scaler1.transform(X_test)\n",
    "X_test = pd.DataFrame(df_minmax_test, columns=X_test.columns)\n",
    "\n",
    "#X_vtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:15.655498700Z",
     "start_time": "2024-03-06T16:13:15.477752Z"
    }
   },
   "outputs": [],
   "source": [
    "# perform One-hot encoding for the train set\n",
    "label_enc = ohe.fit_transform(df_train[categorical_features])\n",
    "label_enc.toarray()\n",
    "new_labels = ohe.get_feature_names_out(categorical_features)\n",
    "df_enc = pd.DataFrame(data=label_enc.toarray(), columns=new_labels)\n",
    "X_train = pd.concat([X_train, df_enc], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:15.781860800Z",
     "start_time": "2024-03-06T16:13:15.606601600Z"
    }
   },
   "outputs": [],
   "source": [
    "# perform One-hot encoding for the validation set\n",
    "label_enc = ohe.transform(df_val[categorical_features])\n",
    "label_enc.toarray()\n",
    "new_labels = ohe.get_feature_names_out(categorical_features)\n",
    "df_enc = pd.DataFrame(data=label_enc.toarray(), columns=new_labels)\n",
    "X_validate = pd.concat([X_validate, df_enc], axis=1)\n",
    "\n",
    "#X_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:15.815704300Z",
     "start_time": "2024-03-06T16:13:15.685965900Z"
    }
   },
   "outputs": [],
   "source": [
    "# perform One-hot encoding for the test set\n",
    "label_enc = ohe.transform(df_test[categorical_features])\n",
    "label_enc.toarray()\n",
    "new_labels = ohe.get_feature_names_out(categorical_features)\n",
    "df_enc = pd.DataFrame(data=label_enc.toarray(), columns=new_labels)\n",
    "X_test = pd.concat([X_test, df_enc], axis=1)\n",
    "\n",
    "#X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:15.849933400Z",
     "start_time": "2024-03-06T16:13:15.759626100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the whole train set:  (88181, 100)\n",
      "Shape of its targets:  (88181,)\n",
      "Shape of the whole train set:  (37792, 100)\n",
      "Shape of its targets:  (37792,)\n",
      "Shape of the whole test set:  (22544, 100)\n",
      "Shape of its targets:  (22544,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of the whole train set: ', X_train.shape)\n",
    "print('Shape of its targets: ', y_train_l1.shape)\n",
    "print('Shape of the whole train set: ', X_validate.shape)\n",
    "print('Shape of its targets: ', y_validate_l1.shape)\n",
    "print('Shape of the whole test set: ', X_test.shape)\n",
    "print('Shape of its targets: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Export the dataset for training layer 1\n",
    "if EXPORT_DATASETS:\n",
    "    X_train.to_csv('EvalResources/ProcessedDatasets/x_train_l1.txt', index=False)\n",
    "    X_validate.to_csv('EvalResources/ProcessedDatasets/x_val_l1.txt', index=False)\n",
    "    np.save('EvalResources/ProcessedWithPCA/y_train_l1', y_train_l1)\n",
    "    np.save('EvalResources/ProcessedWithPCA/y_val_l1', y_validate_l1)\n",
    "    np.save('EvalResources/ProcessedWithPCA/y_test_l1', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:17.313031400Z",
     "start_time": "2024-03-06T16:13:15.848956600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(88181, 28)"
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_dos_probe = PCA(n_components=0.95)\n",
    "X_train_dos_probe = pca_dos_probe.fit_transform(X_train)\n",
    "X_test_dos_probe = pca_dos_probe.transform(X_test)\n",
    "X_validate_dos_probe = pca_dos_probe.transform(X_validate)\n",
    "\n",
    "# X_train = X_train.sort_index(axis=1)\n",
    "X_train_dos_probe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "if EXPORT_PCA:\n",
    "    # save the pca transformed datasets for layer1\n",
    "    column_names = [f'PC{i}' for i in range(1, X_test_dos_probe.shape[1] + 1)]\n",
    "    x = pd.DataFrame(data=X_test_dos_probe, columns=column_names)\n",
    "    x.to_csv('EvalResources/ProcessedDatasets/KDDTest+_l1_pca.txt', index=False)\n",
    "    \n",
    "    column_names = [f'PC{i}' for i in range(1, X_train_dos_probe.shape[1] + 1)]\n",
    "    x = pd.DataFrame(data=X_train_dos_probe, columns=column_names)\n",
    "    x.to_csv('EvalResources/ProcessedDatasets/KDDTrain+_l1_pca.txt', index=False)\n",
    "    \n",
    "    column_names = [f'PC{i}' for i in range(1, X_validate_dos_probe.shape[1] + 1)]\n",
    "    x = pd.DataFrame(data=X_validate_dos_probe, columns=column_names)\n",
    "    x.to_csv('EvalResources/ProcessedDatasets/KDDValidate+_l1_pca.txt', index=False)\n",
    "    \n",
    "    # save the correspondant target values\n",
    "    np.save(\"EvalResources/ProcessedDatasets//KDDTrain+_l1_targets\", y_train_l1)\n",
    "    np.save(\"EvalResources/ProcessedDatasets/KDDValidate+_l1_targets\", y_validate_l1)\n",
    "    np.save(\"EvalResources/ProcessedDatasets//KDDTest+_l1_targets\", y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Building the classifier for the layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:17.336361800Z",
     "start_time": "2024-03-06T16:13:17.265139100Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:13:17.488215300Z",
     "start_time": "2024-03-06T16:13:17.270754900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Voting classifiers\n",
    "\n",
    "voting_classifiers = []"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "# Using HistGradientBoosting classifier\n",
    "dos_probe_classifier = HistGradientBoostingClassifier()\n",
    "\n",
    "start = datetime.now()\n",
    "dos_probe_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "ttime = datetime.now() - start\n",
    "\n",
    "\n",
    "voting_classifiers.append((\"hgbc\", dos_probe_classifier))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "outputs": [],
   "source": [
    "# Using Random Forest Classifier\n",
    "dos_probe_classifier = RandomForestClassifier()\n",
    "\n",
    "start = datetime.now()\n",
    "dos_probe_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "ttime = datetime.now() - start\n",
    "\n",
    "voting_classifiers.append((\"rf\", dos_probe_classifier))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:28.803469300Z",
     "start_time": "2024-03-06T16:13:17.314551400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "predicted = dos_probe_classifier.predict(X_test_dos_probe)\n",
    "\n",
    "print('Metrics for layer 1:')\n",
    "print('Confusion matrix: [TP FN / FP TN]\\n', confusion_matrix(y_test,predicted))\n",
    "print('Accuracy = ', accuracy_score(y_test,predicted))\n",
    "print('F1 Score = ', f1_score(y_test,predicted))\n",
    "print('Precision = ', precision_score(y_test,predicted))\n",
    "print('Recall = ', recall_score(y_test,predicted))\n",
    "print('Train time = ', ttime)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# test the other classifiers obtained in the evaluation phase\n",
    "dos_probe_classifier = joblib.load(\"TunerProcess/TunedModels/l1_classifier.pkl\")\n",
    "#classifier2 = joblib.load(\"TunerProcess/TunedModels/l1_classifier.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using the Naive Bayes Classifier\n",
    "dos_probe_classifier = GaussianNB()\n",
    "\n",
    "voting_classifiers.append((\"nbc\", dos_probe_classifier))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "start = datetime.now()\n",
    "dos_probe_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "ttime = datetime.now() - start\n",
    "\n",
    "predicted = dos_probe_classifier.predict(X_test_dos_probe)\n",
    "\n",
    "print('Metrics for layer 1:')\n",
    "print('Confusion matrix: [TP FN / FP TN]\\n', confusion_matrix(y_test,predicted))\n",
    "print('Accuracy = ', accuracy_score(y_test,predicted))\n",
    "print('F1 Score = ', f1_score(y_test,predicted))\n",
    "print('Precision = ', precision_score(y_test,predicted))\n",
    "print('Recall = ', recall_score(y_test,predicted))\n",
    "print('Train time = ', ttime)\n",
    "print('Shape of the train set for l1: ', X_train_dos_probe.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Voting classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "dos_probe_classifier = VotingClassifier(estimators=voting_classifiers, voting='soft')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "start = datetime.now()\n",
    "dos_probe_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "ttime = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "predicted = dos_probe_classifier.predict(X_test_dos_probe)\n",
    "\n",
    "print('Using a voting classifier:')\n",
    "print('Confusion matrix: [TP FN / FP TN]\\n', confusion_matrix(y_test,predicted))\n",
    "print('Accuracy = ', accuracy_score(y_test,predicted))\n",
    "print('F1 Score = ', f1_score(y_test,predicted))\n",
    "print('Precision = ', precision_score(y_test,predicted))\n",
    "print('Recall = ', recall_score(y_test,predicted))\n",
    "print('Train time = ', ttime)\n",
    "print('Shape of the train set for l1: ', X_train_dos_probe.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R2L+U2R classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:28.906286Z",
     "start_time": "2024-03-06T16:14:28.804477900Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = copy.deepcopy(df_train_original)\n",
    "df_test = copy.deepcopy(df_test_original)\n",
    "df_val = copy.deepcopy(df_val_original)\n",
    "\n",
    "# load targeted attacks (Normal + r2l + u2r)\n",
    "df_train = df_train[df_train['label'].isin(normal_list+u2r_attacks+r2l_attacks)]\n",
    "df_val = df_val[df_val['label'].isin(normal_list+u2r_attacks+r2l_attacks)]\n",
    "df_test = df_test[df_test['label'].isin(normal_list+u2r_attacks+r2l_attacks)]\n",
    "\n",
    "# set the target variables accordingly\n",
    "y_train_l2 = np.array([1 if x in (u2r_attacks+r2l_attacks) else 0 for x in df_train['label']])\n",
    "y_validate_l2 = np.array([1 if x in (u2r_attacks+r2l_attacks) else 0 for x in df_val['label']])\n",
    "y_test = np.array([1 if x in (u2r_attacks+r2l_attacks) else 0 for x in df_test['label']])\n",
    "\n",
    "df_train = df_train.drop(['label'],axis=1)\n",
    "df_train = df_train.reset_index().drop(['index'], axis=1)\n",
    "#df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:28.934604900Z",
     "start_time": "2024-03-06T16:14:28.906286Z"
    }
   },
   "outputs": [],
   "source": [
    "df_val = df_val.drop(['label'],axis=1)\n",
    "df_val = df_val.reset_index().drop(['index'], axis=1)\n",
    "#df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:28.998922700Z",
     "start_time": "2024-03-06T16:14:28.922592800Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = df_test.drop(['label'],axis=1)\n",
    "df_test = df_test.reset_index().drop(['index'], axis=1)\n",
    "#df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:29.049402700Z",
     "start_time": "2024-03-06T16:14:28.935702400Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df_train\n",
    "X_validate = df_val\n",
    "X_test = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Using features obtained with a random forest on numerical features only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# List of feature names\n",
    "feature_names_l2 = ['count', 'is_guest_login', 'srv_count', 'hot', 'dst_host_serror_rate',\n",
    "       'dst_host_srv_count', 'dst_host_count', 'dst_host_same_srv_rate',\n",
    "       'dst_host_same_src_port_rate', 'num_file_creations', 'diff_srv_rate']\n",
    "\n",
    "# Selecting features using loc\n",
    "X_train = df_train.loc[:, feature_names_l2]\n",
    "X_validate = df_val.loc[:, feature_names_l2]\n",
    "X_test = df_test.loc[:, feature_names_l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:29.053424800Z",
     "start_time": "2024-03-06T16:14:28.946363300Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df_train[common_features_l2]\n",
    "X_validate = df_val[common_features_l2]\n",
    "X_test = df_test[common_features_l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:29.070703600Z",
     "start_time": "2024-03-06T16:14:28.956079200Z"
    }
   },
   "outputs": [],
   "source": [
    "df_minmax = scaler2.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(df_minmax, columns=X_train.columns)\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:29.075597900Z",
     "start_time": "2024-03-06T16:14:28.971689500Z"
    }
   },
   "outputs": [],
   "source": [
    "df_minmax = scaler2.transform(X_validate)\n",
    "X_validate = pd.DataFrame(df_minmax, columns=X_validate.columns)\n",
    "#X_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:29.080249600Z",
     "start_time": "2024-03-06T16:14:28.981708Z"
    }
   },
   "outputs": [],
   "source": [
    "df_minmax = scaler2.transform(X_test)\n",
    "X_test = pd.DataFrame(df_minmax, columns=X_test.columns)\n",
    "#X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:29.171389Z",
     "start_time": "2024-03-06T16:14:28.996860900Z"
    }
   },
   "outputs": [],
   "source": [
    "# perform One-hot encoding for the train set\n",
    "label_enc = ohe2.fit_transform(df_train[categorical_features])\n",
    "label_enc.toarray()\n",
    "new_labels = ohe2.get_feature_names_out(categorical_features)\n",
    "df_enc = pd.DataFrame(data=label_enc.toarray(), columns=new_labels)\n",
    "X_train = pd.concat([X_train, df_enc], axis=1)\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:29.198597600Z",
     "start_time": "2024-03-06T16:14:29.045945200Z"
    }
   },
   "outputs": [],
   "source": [
    "# perform One-hot encoding for the validation set\n",
    "label_enc = ohe2.transform(df_val[categorical_features])\n",
    "label_enc.toarray()\n",
    "new_labels = ohe2.get_feature_names_out(categorical_features)\n",
    "df_enc = pd.DataFrame(data=label_enc.toarray(), columns=new_labels)\n",
    "X_validate = pd.concat([X_validate, df_enc], axis=1)\n",
    "#X_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:29.223926800Z",
     "start_time": "2024-03-06T16:14:29.069703500Z"
    }
   },
   "outputs": [],
   "source": [
    "# perform One-hot encoding for the test set\n",
    "label_enc = ohe2.transform(df_test[categorical_features])\n",
    "label_enc.toarray()\n",
    "new_labels = ohe2.get_feature_names_out(categorical_features)\n",
    "df_enc = pd.DataFrame(data=label_enc.toarray(), columns=new_labels)\n",
    "X_test = pd.concat([X_test, df_enc], axis=1)\n",
    "#X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:29.243949900Z",
     "start_time": "2024-03-06T16:14:29.095002600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train set:  (47873, 51)\n",
      "Shape of its target:  (47873,)\n",
      "Shape of the test set:  (12663, 51)\n",
      "Shape of its target:  (12663,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of the train set: ', X_train.shape)\n",
    "print('Shape of its target: ', y_train_l2.shape)\n",
    "print('Shape of the test set: ', X_test.shape)\n",
    "print('Shape of its target: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:29.342368500Z",
     "start_time": "2024-03-06T16:14:29.099347200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Under sampling the train set for l2\n",
    "sm = under_sam(sampling_strategy=1)\n",
    "X_train, y_train_l2 = sm.fit_resample(X_train,y_train_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Export the datasets\n",
    "Train set has been scaled, one hot encoded, undersampled\n",
    "Test set has been scaled and one hot encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Export the dataset for training layer 2\n",
    "if EXPORT_DATASETS:\n",
    "    # X_train.to_csv('EvalResources/ProcessedDatasets/x_train_l2.txt', index=False)\n",
    "    np.save('EvalResources/ProcessedWithPCA/y_train_l2', y_train_l2)\n",
    "    # X_validate.to_csv('EvalResources/ProcessedDatasets/x_val_l2.txt', index=False)\n",
    "    np.save('EvalResources/ProcessedWithPCA/y_val_l2', y_val)\n",
    "    np.save('EvalResources/ProcessedWithPCA/y_test_l2', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:29.377578300Z",
     "start_time": "2024-03-06T16:14:29.120117Z"
    }
   },
   "outputs": [],
   "source": [
    "# Principal Component Analysis\n",
    "pca_r2l_u2r = PCA(n_components=0.95)\n",
    "X_train_r2l_u2r = pca_r2l_u2r.fit_transform(X_train)\n",
    "X_test_r2l_u2r = pca_r2l_u2r.transform(X_test)\n",
    "X_validate_r2l_u2r = pca_r2l_u2r.transform(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:29.437972300Z",
     "start_time": "2024-03-06T16:14:29.159658400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Support Vector Machine for layer l2\n",
    "r2l_u2r_classifier = SVC(probability=True)\n",
    "\n",
    "#r2l_u2r_classifier = SVC()\n",
    "\n",
    "start = datetime.now()\n",
    "r2l_u2r_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "ttime = datetime.now() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "predicted = r2l_u2r_classifier.predict(X_test_r2l_u2r)\n",
    "\n",
    "print('Metrics for layer 2:')\n",
    "print('Confusion matrix: [TP FN / FP TN]\\n', confusion_matrix(y_test,predicted))\n",
    "print('Accuracy = ', accuracy_score(y_test,predicted))\n",
    "print('F1 Score = ', f1_score(y_test,predicted))\n",
    "print('Precision = ', precision_score(y_test,predicted))\n",
    "print('Recall = ', recall_score(y_test,predicted))\n",
    "print('Matthew corr = ', matthews_corrcoef(y_test,predicted))\n",
    "print('Train time = ', ttime)\n",
    "print('Shape of the training set: ', X_train_r2l_u2r.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "predicted = r2l_u2r_classifier.predict(X_train_r2l_u2r)\n",
    "\n",
    "print('Metrics for layer 2:')\n",
    "print('Confusion matrix: [TP FN / FP TN]\\n', confusion_matrix(y_train_l2,predicted))\n",
    "print('Accuracy = ', accuracy_score(y_train_l2,predicted))\n",
    "print('F1 Score = ', f1_score(y_train_l2,predicted))\n",
    "print('Precision = ', precision_score(y_train_l2,predicted))\n",
    "print('Recall = ', recall_score(y_train_l2,predicted))\n",
    "print('Matthew corr = ', matthews_corrcoef(y_train_l2,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "if EXPORT_PCA:\n",
    "    # save the pca transformed as well as the transformer\n",
    "    column_names = [f'PC{i}' for i in range(1, X_test_r2l_u2r.shape[1] + 1)]\n",
    "    x = pd.DataFrame(data=X_test_r2l_u2r, columns=column_names)\n",
    "    x.to_csv('EvalResources/ProcessedDatasets/KDDTest+_l2_pca.txt', index=False)\n",
    "    \n",
    "    column_names = [f'PC{i}' for i in range(1, X_train_r2l_u2r.shape[1] + 1)]\n",
    "    x = pd.DataFrame(data=X_train_r2l_u2r, columns=column_names)\n",
    "    x.to_csv('EvalResources/ProcessedDatasets/KDDTrain+_l2_pca.txt', index=False)\n",
    "    \n",
    "    column_names = [f'PC{i}' for i in range(1, X_validate_r2l_u2r.shape[1] + 1)]\n",
    "    x = pd.DataFrame(data=X_validate_r2l_u2r, columns=column_names)\n",
    "    x.to_csv('EvalResources/ProcessedDatasets/KDDValidate+_l2_pca.txt', index=False)\n",
    "\n",
    "    # export the correspondant targets values\n",
    "    np.save(\"EvalResources/ProcessedDatasets//KDDTrain+_l2_targets\", y_train_l2)\n",
    "    np.save(\"EvalResources/ProcessedDatasets/KDDValidate+_l2_targets\", y_validate_l2)\n",
    "    np.save(\"EvalResources/ProcessedDatasets//KDDTest+_l2_targets\", y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Export the classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "if EXPORT_MODELS:\n",
    "    with open('EvalResources/Models/HGBC/l1_classifier.pkl', \"wb\") as f:\n",
    "        pickle.dump(dos_probe_classifier, f)\n",
    "    with open('EvalResources/Models/HGBC/l2_classifier.pkl', \"wb\") as f:\n",
    "        pickle.dump(r2l_u2r_classifier, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Export one hot encoders\n",
    "if EXPORT_ENCODERS:\n",
    "    joblib.dump(ohe, 'EvalResources/Encoders/ohe_l1.pkl')\n",
    "    joblib.dump(ohe2, 'EvalResources/Encoders/ohe_l2.pkl')\n",
    "    joblib.dump(scaler1, 'EvalResources/Encoders/Scaler_l1.pkl')\n",
    "    joblib.dump(scaler2, 'EvalResources/Encoders/Scaler_l2.pkl')\n",
    "    joblib.dump(pca_dos_probe, 'EvalResources/Encoders/pca_transformer_l1.pkl')\n",
    "    joblib.dump(pca_r2l_u2r, 'EvalResources/Encoders/pca_transformer_l2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:29.459294800Z",
     "start_time": "2024-03-06T16:14:29.232323900Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test1 = copy.deepcopy(df_test_original)\n",
    "df_test2 = copy.deepcopy(df_test_original)\n",
    "\n",
    "y_test_real = np.array([0 if x=='normal' else 1 for x in df_test1['label']])\n",
    "\n",
    "np.save(\"EvalResources/Test/KDDTest+_targets\", y_test_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:29.464421300Z",
     "start_time": "2024-03-06T16:14:29.247747700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(22544,)"
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_real.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "X_test1 = df_test1.loc[:, feature_names_l1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:29.484352300Z",
     "start_time": "2024-03-06T16:14:29.255579500Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test1 = df_test1[common_features_l1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:29.613281200Z",
     "start_time": "2024-03-06T16:14:29.263385700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set shape for layer 1:  (22544, 28)\n"
     ]
    }
   ],
   "source": [
    "df_minmax = scaler1.transform(X_test1)\n",
    "X_test1 = pd.DataFrame(df_minmax, columns=X_test1.columns)\n",
    "label_enc = ohe.transform(df_test1.iloc[:,1:4])\n",
    "label_enc.toarray()\n",
    "new_labels = ohe.get_feature_names_out(categorical_features)\n",
    "df_enc = pd.DataFrame(data=label_enc.toarray(), columns=new_labels)\n",
    "X_test1 = pd.concat([X_test1, df_enc], axis=1)\n",
    "\n",
    "X_test_layer1 = pca_dos_probe.transform(X_test1)\n",
    "print('Test set shape for layer 1: ', X_test_layer1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:29.618238100Z",
     "start_time": "2024-03-06T16:14:29.323105800Z"
    }
   },
   "outputs": [],
   "source": [
    "#X_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:29.633639400Z",
     "start_time": "2024-03-06T16:14:29.329831200Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test2 = df_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "X_test2 = df_test2.loc[:, feature_names_l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:29.636234900Z",
     "start_time": "2024-03-06T16:14:29.332784400Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test2 = df_test2[common_features_l2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:29.695821900Z",
     "start_time": "2024-03-06T16:14:29.341339300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set shape for layer 1:  (22544, 28)\n",
      "Test set shape for layer 2:  (22544, 13)\n"
     ]
    }
   ],
   "source": [
    "df_minmax = scaler2.transform(X_test2)\n",
    "X_test2 = pd.DataFrame(df_minmax, columns=X_test2.columns)\n",
    "label_enc = ohe2.transform(df_test2.iloc[:,1:4])\n",
    "label_enc.toarray()\n",
    "new_labels = ohe2.get_feature_names_out(categorical_features)\n",
    "df_enc = pd.DataFrame(data=label_enc.toarray(), columns=new_labels)\n",
    "X_test2 = pd.concat([X_test2, df_enc], axis=1)\n",
    "\n",
    "X_test_layer2 = pca_r2l_u2r.transform(X_test2)\n",
    "print('Test set shape for layer 1: ', X_test_layer1.shape)\n",
    "print('Test set shape for layer 2: ', X_test_layer2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:29.713093900Z",
     "start_time": "2024-03-06T16:14:29.391520500Z"
    }
   },
   "outputs": [],
   "source": [
    "#X_test_layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:29.719269600Z",
     "start_time": "2024-03-06T16:14:29.396397800Z"
    }
   },
   "outputs": [],
   "source": [
    "#X_test_layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:29.735359600Z",
     "start_time": "2024-03-06T16:14:29.401467300Z"
    }
   },
   "outputs": [],
   "source": [
    "# same classifiers obtained above\n",
    "classifier1 = dos_probe_classifier\n",
    "classifier2 = r2l_u2r_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:14:29.740728300Z",
     "start_time": "2024-03-06T16:14:29.409755Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppressing the warning\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names.*\")\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def test_metrics():\n",
    "    result_ = []\n",
    "    tn, fp, fn, tp = 0, 0, 0, 0\n",
    "    \n",
    "    start_ = datetime.now()\n",
    "    \n",
    "    for i in range(X_test_layer2.shape[0]):\n",
    "        layer1_ = classifier1.predict(X_test_layer1[i].reshape(1, -1))[0]\n",
    "        if layer1_ == 1:\n",
    "            result_.append(layer1_)\n",
    "        else:\n",
    "            layer2_ = classifier2.predict(X_test_layer2[i].reshape(1, -1))[0]\n",
    "            if layer2_ == 1:\n",
    "                result_.append(layer2_)\n",
    "            else:\n",
    "                result_.append(0)\n",
    "        # Evaluate confusion matrix\n",
    "        if y_test_real[i] == 1:\n",
    "            if result_[-1] == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "        else:\n",
    "            if result_[-1] == 1:\n",
    "                fp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "    \n",
    "    clf_time_ = datetime.now() - start_\n",
    "    \n",
    "    # Calculate rates\n",
    "    tnr_ = tn / (tn + fp)\n",
    "    fpr_= fp / (fp + tn)\n",
    "    fnr_ = fn / (fn + tp)\n",
    "    \n",
    "    return (accuracy_score(y_test_real,np.array(result_)), \n",
    "            f1_score(y_test_real, np.array(result_)),\n",
    "            precision_score(y_test_real, np.array(result_)),\n",
    "            recall_score(y_test_real, np.array(result_)),\n",
    "            clf_time_, tnr_, fpr_, fnr_, np.array(result_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.7982611781405252\n",
      "F1 Score =  0.7939097335508429\n",
      "Precision =  0.9485652409312398\n",
      "Recall =  0.6826151328605938\n",
      "Classification time =  0:01:45.432754\n",
      "False Positive Rate (FPR) = 0.0489136031304706\n",
      "True Negative Rate (TNR) = 0.9510863968695294\n",
      "False Negative Rate (FNR) = 0.3173848671394062\n"
     ]
    }
   ],
   "source": [
    "# the results may vary\n",
    "accuracy, f_score, precision, recall, clf_time, tnr, fpr, fnr, result = test_metrics()\n",
    "\n",
    "print('Accuracy = ', accuracy)\n",
    "print('F1 Score = ', f_score)\n",
    "print('Precision = ', precision)\n",
    "print('Recall = ', recall)\n",
    "print('Classification time = ', clf_time)\n",
    "print('False Positive Rate (FPR) =', fpr)\n",
    "print('True Negative Rate (TNR) =', tnr)\n",
    "print('False Negative Rate (FNR) =', fnr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:16:14.902830900Z",
     "start_time": "2024-03-06T16:14:29.417082800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run the function multiple times and accumulate results\n",
    "num_iterations = 5\n",
    "total_accuracy = 0\n",
    "total_f1_score = 0\n",
    "total_precision = 0\n",
    "total_recall = 0\n",
    "total_clf_time = 0\n",
    "total_tnr = 0\n",
    "total_fpr = 0\n",
    "total_fnr = 0\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    acc, f1, prec, rec, clf_time, tnr, fpr, fnr, _ = test_metrics()\n",
    "    total_accuracy += acc\n",
    "    total_f1_score += f1\n",
    "    total_precision += prec\n",
    "    total_recall += rec\n",
    "    total_tnr += tnr\n",
    "    total_fpr += fpr\n",
    "    total_fnr += fnr\n",
    "\n",
    "# Calculate averages\n",
    "avg_accuracy = total_accuracy / num_iterations\n",
    "avg_f1_score = total_f1_score / num_iterations\n",
    "avg_precision = total_precision / num_iterations\n",
    "avg_recall = total_recall / num_iterations\n",
    "avg_tnr = total_tnr / num_iterations\n",
    "avg_fpr = total_fpr / num_iterations\n",
    "avg_fnr = total_fnr / num_iterations\n",
    "\n",
    "print('Average Accuracy:', avg_accuracy)\n",
    "print('Average F1 Score:', avg_f1_score)\n",
    "print('Average Precision:', avg_precision)\n",
    "print('Average Recall:', avg_recall)\n",
    "print('Average TNR:', avg_tnr)\n",
    "print('Average FPR:', avg_fpr)\n",
    "print('Average FNR:', avg_fnr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new attacks in the test set:  3750\n",
      "Number of new attacks detected by the classifiers:  1358\n",
      "Proportion of new attacks detected:  0.3621333333333333\n",
      "Number of old attacks in the test set:  9083\n",
      "Number of old attacks detected by the classifiers:  7402\n",
      "Proportion of old attacks detected:  0.8149289882197512\n"
     ]
    }
   ],
   "source": [
    "# load testset\n",
    "df_test = pd.read_csv('EvalResources/KDDTest+.txt', sep=\",\", header=None, skipinitialspace=True)\n",
    "df_test = df_test[df_test.columns[:-1]]\n",
    "df_test.columns = titles.to_list()\n",
    "y_test = df_test['label']\n",
    "df_test = df_test.drop(['num_outbound_cmds'], axis=1)\n",
    "\n",
    "df_test_original = df_test\n",
    "if EXPORT_DATASETS:\n",
    "    df_test_original.to_csv('EvalResources/ProcessedDatasets/x_test_full.txt', index=False)\n",
    "    np.save('EvalResources/ProcessedDatasets/y_test_full', y_test)\n",
    "\n",
    "#df_test_original\n",
    "new_attack = []\n",
    "for i in df_test_original['label'].value_counts().index.tolist()[1:]:\n",
    "    if i not in df_train_original['label'].value_counts().index.tolist()[1:]:\n",
    "        new_attack.append(i)\n",
    "\n",
    "new_attack.sort()\n",
    "#new_attack\n",
    "index_of_new_attacks = []\n",
    "\n",
    "for i in range(len(df_test_original)):\n",
    "    if df_test_original['label'][i] in new_attack:\n",
    "        index_of_new_attacks.append(df_test_original.index[i])\n",
    "\n",
    "new_attack.append('normal')\n",
    "\n",
    "index_of_old_attacks = []\n",
    "\n",
    "for i in range(len(df_test_original)):\n",
    "    if df_test_original['label'][i] not in new_attack:\n",
    "        index_of_old_attacks.append(df_test_original.index[i])\n",
    "print('Number of new attacks in the test set: ', result[index_of_new_attacks].shape[0])\n",
    "print('Number of new attacks detected by the classifiers: ', result[index_of_new_attacks].sum())\n",
    "print('Proportion of new attacks detected: ',\n",
    "      result[index_of_new_attacks].sum() / result[index_of_new_attacks].shape[0])\n",
    "print('Number of old attacks in the test set: ', result[index_of_old_attacks].shape[0])\n",
    "print('Number of old attacks detected by the classifiers: ', result[index_of_old_attacks].sum())\n",
    "print('Proportion of old attacks detected: ',\n",
    "      result[index_of_old_attacks].sum() / result[index_of_old_attacks].shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:16:15.308993600Z",
     "start_time": "2024-03-06T16:16:14.896301700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of DOS detection:  0.7777479892761394\n",
      "Ratio of PROBE detection:  0.8194960760016522\n",
      "Ratio of U2R detection:  0.32062391681109187\n",
      "Ratio of R2L detection:  0.7313432835820896\n",
      "New attacks detected:  0.3621333333333333\n",
      "Old attacks detected:  0.8149289882197512\n"
     ]
    }
   ],
   "source": [
    "### Evaluate single attack types\n",
    "# load test set\n",
    "df_test = pd.read_csv('EvalResources/KDDTest+.txt', sep=\",\", header=None, skipinitialspace=True)\n",
    "df_test = df_test[df_test.columns[:-1]]\n",
    "df_test.columns = titles.to_list()\n",
    "y_test = df_test['label']\n",
    "df_test = df_test.drop(['num_outbound_cmds'], axis=1)\n",
    "df_test_original = df_test\n",
    "df = df_test_original\n",
    "\n",
    "dos_index = df.index[(df['label'].isin(dos_attacks))].tolist()\n",
    "probe_index = df.index[(df['label'].isin(probe_attacks))].tolist()\n",
    "r2l_index = df.index[(df['label'].isin(r2l_attacks))].tolist()\n",
    "u2r_index = df.index[(df['label'].isin(u2r_attacks))].tolist()\n",
    "\n",
    "print(\"Ratio of DOS detection: \", result[dos_index].sum() / result[dos_index].shape[0])\n",
    "\n",
    "print(\"Ratio of PROBE detection: \", result[probe_index].sum() / result[probe_index].shape[0])\n",
    "\n",
    "print(\"Ratio of U2R detection: \", result[r2l_index].sum() / result[r2l_index].shape[0])\n",
    "\n",
    "print(\"Ratio of R2L detection: \", result[u2r_index].sum() / result[u2r_index].shape[0])\n",
    "\n",
    "print('New attacks detected: ',\n",
    "      result[index_of_new_attacks].sum() / result[index_of_new_attacks].shape[0])\n",
    "\n",
    "print('Old attacks detected: ',\n",
    "      result[index_of_old_attacks].sum() / result[index_of_old_attacks].shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:16:15.407668200Z",
     "start_time": "2024-03-06T16:16:15.307986500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Now start the adaptation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T15:56:34.565757Z",
     "start_time": "2024-03-06T15:56:34.558210300Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S1 RF + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Define the space of hyperparameters for Random Forest\n",
    "rf_params = {\n",
    "    'n_estimators': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_split': optuna.distributions.IntDistribution(2, 20),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "## Define the space of hyperparameters for SVM\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for Random Forest\n",
    "    rf_hyperparams = {\n",
    "        'n_estimators': trial.suggest_int('rf_n_estimators', 10, 70),\n",
    "        'max_depth': trial.suggest_int('rf_max_depth', 2, 32),\n",
    "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize and train Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(**rf_hyperparams)\n",
    "    rf_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    rf_predicted = rf_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    rf_precision = precision_score(y_validate_l1, rf_predicted)\n",
    "    svm_precision = precision_score(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    rf_recall = recall_score(y_validate_l1, rf_predicted)\n",
    "    svm_recall = recall_score(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate weighted average of TPR and Precision (you can adjust weights based on preference)\n",
    "    weighted_score = (0.5 * (rf_recall + svm_recall)) + (0.5 * (rf_precision + svm_precision))\n",
    "    \n",
    "    return weighted_score\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S1 (RF+NBC) + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "rf_params = {\n",
    "    'n_estimators': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_split': optuna.distributions.IntDistribution(2, 20),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "nbc_params = {\n",
    "    'var_smoothing': optuna.distributions.FloatDistribution(1e-10, 1e-1)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for Random Forest\n",
    "    rf_hyperparams = {\n",
    "        'n_estimators': trial.suggest_int('rf_n_estimators', 10, 70),\n",
    "        'max_depth': trial.suggest_int('rf_max_depth', 2, 32),\n",
    "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \n",
    "    \"\"\"\n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for GaussianNB\n",
    "    gnb_hyperparams = {\n",
    "        'var_smoothing': trial.suggest_float('gnb_var_smoothing', 1e-10, 1e-1, log=True)\n",
    "    }\n",
    "    \n",
    "    # Initialize the rf\n",
    "    rf_classifier = RandomForestClassifier(**rf_hyperparams)\n",
    "    \n",
    "    # Initialize the nbc\n",
    "    nbc_classifier = GaussianNB(**gnb_hyperparams)\n",
    "    \n",
    "    # Initialize and train voting classifier\n",
    "    voting_classifier = VotingClassifier(\n",
    "        estimators=[(\"rf\", rf_classifier), (\"nbc\", nbc_classifier)] ,\n",
    "        voting='soft'\n",
    "    )\n",
    "    voting_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    voting_predicted = voting_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    voting_precision = precision_score(y_validate_l1, voting_predicted)\n",
    "    svm_precision = precision_score(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    voting_recall = recall_score(y_validate_l1, voting_predicted)\n",
    "    svm_recall = recall_score(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate weighted average of TPR and Precision (you can adjust weights based on preference)\n",
    "    weighted_score = (0.5 * (voting_recall + svm_recall)) + (0.5 * (voting_precision + svm_precision))\n",
    "    \n",
    "    return weighted_score\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S1 (HGBC+NBC) + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "hgb_params = {\n",
    "    'learning_rate': optuna.distributions.FloatDistribution(0.001, 0.1),\n",
    "    'max_iter': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "nbc_params = {\n",
    "    'var_smoothing': optuna.distributions.FloatDistribution(1e-10, 1e-1)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for HistGradientBoostingClassifier\n",
    "    hgb_hyperparams = {\n",
    "        'learning_rate': trial.suggest_float('hgb_learning_rate', 0.001, 0.1, log=True),\n",
    "        'max_iter': trial.suggest_int('hgb_max_iter', 50, 500),\n",
    "        'max_depth': trial.suggest_int('hgb_max_depth', 2, 32),\n",
    "        'min_samples_leaf': trial.suggest_int('hgb_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for GaussianNB\n",
    "    gnb_hyperparams = {\n",
    "        'var_smoothing': trial.suggest_float('gnb_var_smoothing', 1e-10, 1e-1, log=True)\n",
    "    }\n",
    "    \n",
    "    # Initialize the hgbc\n",
    "    hgbc_classifier = HistGradientBoostingClassifier(**hgb_hyperparams)\n",
    "    \n",
    "    # Initialize the nbc\n",
    "    nbc_classifier = GaussianNB(**gnb_hyperparams)\n",
    "    \n",
    "    # Initialize and train voting classifier\n",
    "    voting_classifier = VotingClassifier(\n",
    "        estimators=[(\"hgbc\", hgbc_classifier), (\"nbc\", nbc_classifier)] ,\n",
    "        voting='soft'\n",
    "    )\n",
    "    voting_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    voting_predicted = voting_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    voting_precision = precision_score(y_validate_l1, voting_predicted)\n",
    "    svm_precision = precision_score(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    voting_recall = recall_score(y_validate_l1, voting_predicted)\n",
    "    svm_recall = recall_score(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate weighted average of TPR and Precision (you can adjust weights based on preference)\n",
    "    weighted_score = (0.5 * (voting_recall + svm_recall)) + (0.5 * (voting_precision + svm_precision))\n",
    "    \n",
    "    return weighted_score\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S1 HGBC + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb_params = {\n",
    "    'learning_rate': optuna.distributions.FloatDistribution(0.001, 0.1),\n",
    "    'max_iter': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for HistGradientBoostingClassifier\n",
    "    hgb_hyperparams = {\n",
    "        'learning_rate': trial.suggest_float('hgb_learning_rate', 0.001, 0.1, log=True),\n",
    "        'max_iter': trial.suggest_int('hgb_max_iter', 50, 500),\n",
    "        'max_depth': trial.suggest_int('hgb_max_depth', 2, 32),\n",
    "        'min_samples_leaf': trial.suggest_int('hgb_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "\n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \n",
    "    \"\"\"\n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize and train HistGradientBoostingClassifier\n",
    "    hgb_classifier = HistGradientBoostingClassifier(**hgb_hyperparams)\n",
    "    hgb_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    hgb_predicted = hgb_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    hgb_precision = precision_score(y_validate_l1, hgb_predicted)\n",
    "    svm_precision = precision_score(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    hgb_recall = recall_score(y_validate_l1, hgb_predicted)\n",
    "    svm_recall = recall_score(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate weighted average of TPR and Precision (you can adjust weights based on preference)\n",
    "    weighted_score = (0.5 * (hgb_recall + svm_recall)) + (0.5 * (hgb_precision + svm_precision))\n",
    "    \n",
    "    return weighted_score\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S2 (RF+NBC) + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "hgb_params = {\n",
    "    'learning_rate': optuna.distributions.FloatDistribution(0.001, 0.1),\n",
    "    'max_iter': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "nbc_params = {\n",
    "    'var_smoothing': optuna.distributions.FloatDistribution(1e-10, 1e-1)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for Random Forest\n",
    "    rf_hyperparams = {\n",
    "        'n_estimators': trial.suggest_int('rf_n_estimators', 10, 70),\n",
    "        'max_depth': trial.suggest_int('rf_max_depth', 2, 32),\n",
    "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for GaussianNB\n",
    "    gnb_hyperparams = {\n",
    "        'var_smoothing': trial.suggest_float('gnb_var_smoothing', 1e-10, 1e-1, log=True)\n",
    "    }\n",
    "    \n",
    "    # Initialize the rf\n",
    "    rf_classifier = RandomForestClassifier(**rf_hyperparams)\n",
    "    \n",
    "    # Initialize the nbc\n",
    "    nbc_classifier = GaussianNB(**gnb_hyperparams)\n",
    "    \n",
    "    # Initialize and train voting classifier\n",
    "    voting_classifier = VotingClassifier(\n",
    "        estimators=[(\"rf\", rf_classifier), (\"nbc\", nbc_classifier)] ,\n",
    "        voting='soft'\n",
    "    )\n",
    "    voting_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    voting_predicted = voting_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    # Calculate confusion matrices for both classifiers\n",
    "    voting_cm = confusion_matrix(y_validate_l1, voting_predicted)\n",
    "    svm_cm = confusion_matrix(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate False Positive Rates for both classifiers\n",
    "    voting_fpr = voting_cm[0, 1] / np.sum(voting_cm[0, :])\n",
    "    svm_fpr = svm_cm[0, 1] / np.sum(svm_cm[0, :])\n",
    "    \n",
    "    # Calculate the average FPR\n",
    "    avg_fpr = (voting_fpr + svm_fpr) / 2\n",
    "    \n",
    "    return avg_fpr\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S2 (HGBC+NBC) + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "hgb_params = {\n",
    "    'learning_rate': optuna.distributions.FloatDistribution(0.001, 0.1),\n",
    "    'max_iter': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for HistGradientBoostingClassifier\n",
    "    hgb_hyperparams = {\n",
    "        'learning_rate': trial.suggest_float('hgb_learning_rate', 0.001, 0.1, log=True),\n",
    "        'max_iter': trial.suggest_int('hgb_max_iter', 50, 500),\n",
    "        'max_depth': trial.suggest_int('hgb_max_depth', 2, 32),\n",
    "        'min_samples_leaf': trial.suggest_int('hgb_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for GaussianNB\n",
    "    gnb_hyperparams = {\n",
    "        'var_smoothing': trial.suggest_float('gnb_var_smoothing', 1e-10, 1e-1, log=True)\n",
    "    }\n",
    "    \n",
    "    # Initialize the rf\n",
    "    hgb_classifier = HistGradientBoostingClassifier(**hgb_hyperparams)\n",
    "    \n",
    "    # Initialize the nbc\n",
    "    nbc_classifier = GaussianNB(**gnb_hyperparams)\n",
    "    \n",
    "    # Initialize and train voting classifier\n",
    "    voting_classifier = VotingClassifier(\n",
    "        estimators=[(\"hgbc\", hgb_classifier), (\"nbc\", nbc_classifier)] ,\n",
    "        voting='soft'\n",
    "    )\n",
    "    voting_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    voting_predicted = voting_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    # Calculate confusion matrices for both classifiers\n",
    "    voting_cm = confusion_matrix(y_validate_l1, voting_predicted)\n",
    "    svm_cm = confusion_matrix(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate False Positive Rates for both classifiers\n",
    "    voting_fpr = voting_cm[0, 1] / np.sum(voting_cm[0, :])\n",
    "    svm_fpr = svm_cm[0, 1] / np.sum(svm_cm[0, :])\n",
    "    \n",
    "    # Calculate the average FPR\n",
    "    avg_fpr = (voting_fpr + svm_fpr) / 2\n",
    "    \n",
    "    return avg_fpr\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S2 HGBC + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "hgb_params = {\n",
    "    'learning_rate': optuna.distributions.FloatDistribution(0.001, 0.1),\n",
    "    'max_iter': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for HistGradientBoostingClassifier\n",
    "    hgb_hyperparams = {\n",
    "        'learning_rate': trial.suggest_float('hgb_learning_rate', 0.001, 0.1, log=True),\n",
    "        'max_iter': trial.suggest_int('hgb_max_iter', 50, 500),\n",
    "        'max_depth': trial.suggest_int('hgb_max_depth', 2, 32),\n",
    "        'min_samples_leaf': trial.suggest_int('hgb_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for GaussianNB\n",
    "    gnb_hyperparams = {\n",
    "        'var_smoothing': trial.suggest_float('gnb_var_smoothing', 1e-10, 1e-1, log=True)\n",
    "    }\n",
    "    \n",
    "    # Initialize the rf\n",
    "    hgb_classifier = HistGradientBoostingClassifier(**hgb_hyperparams)\n",
    "    hgb_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    hgb_predicted = hgb_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    # Calculate confusion matrices for both classifiers\n",
    "    hgb_cm = confusion_matrix(y_validate_l1, hgb_predicted)\n",
    "    svm_cm = confusion_matrix(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate False Positive Rates for both classifiers\n",
    "    voting_fpr = hgb_cm[0, 1] / np.sum(hgb_cm[0, :])\n",
    "    svm_fpr = svm_cm[0, 1] / np.sum(svm_cm[0, :])\n",
    "    \n",
    "    # Calculate the average FPR\n",
    "    avg_fpr = (voting_fpr + svm_fpr) / 2\n",
    "    \n",
    "    return avg_fpr\n",
    "    \n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S2 RF + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "rf_params = {\n",
    "    'n_estimators': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_split': optuna.distributions.IntDistribution(2, 20),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "nbc_params = {\n",
    "    'var_smoothing': optuna.distributions.FloatDistribution(1e-10, 1e-1)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for Random Forest\n",
    "    rf_hyperparams = {\n",
    "        'n_estimators': trial.suggest_int('rf_n_estimators', 10, 70),\n",
    "        'max_depth': trial.suggest_int('rf_max_depth', 2, 32),\n",
    "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    \"\"\"\n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \n",
    "    # Initialize and train HistGradientBoostingClassifier\n",
    "    rf_classifier = RandomForestClassifier(**rf_hyperparams)\n",
    "    rf_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    hgb_predicted = rf_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    # Calculate confusion matrices for both classifiers\n",
    "    hgb_cm = confusion_matrix(y_validate_l1, hgb_predicted)\n",
    "    svm_cm = confusion_matrix(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate False Positive Rates for both classifiers\n",
    "    rf_fpr = hgb_cm[0, 1] / np.sum(hgb_cm[0, :])\n",
    "    svm_fpr = svm_cm[0, 1] / np.sum(svm_cm[0, :])\n",
    "    \n",
    "    # Calculate the average FPR\n",
    "    avg_fpr = (rf_fpr + svm_fpr) / 2\n",
    "    \n",
    "    return avg_fpr\n",
    "    \n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S3 RF + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "import optuna\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_split': optuna.distributions.IntDistribution(2, 20),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for Random Forest\n",
    "    rf_hyperparams = {\n",
    "        'n_estimators': trial.suggest_int('rf_n_estimators', 10, 70),\n",
    "        'max_depth': trial.suggest_int('rf_max_depth', 2, 32),\n",
    "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    \"\"\"\n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \n",
    "    # Initialize and train Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(**rf_hyperparams)\n",
    "    \n",
    "    # Initialize the NBC\n",
    "    nbc_classifier = GaussianNB(**nbc_params)\n",
    "    \n",
    "    # Initialize and train voting classifier\n",
    "    voting_classifier = VotingClassifier(\n",
    "        estimators=[(\"rf\", rf_classifier), (\"nbc\", nbc_classifier)] ,\n",
    "        voting='soft'\n",
    "    )\n",
    "    voting_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    voting_predicted = voting_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    # Calculate confusion matrices for both classifiers\n",
    "    voting_cm = confusion_matrix(y_validate_l1, voting_predicted)\n",
    "    svm_cm = confusion_matrix(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate False Positive Rates (FPR) and True Negative Rates (TNR) for both classifiers\n",
    "    voting_fpr = voting_cm[0, 1] / np.sum(voting_cm[0, :])\n",
    "    voting_tnr = voting_cm[0, 0] / np.sum(voting_cm[0, :])\n",
    "    \n",
    "    svm_fpr = svm_cm[0, 1] / np.sum(svm_cm[0, :])\n",
    "    svm_tnr = svm_cm[0, 0] / np.sum(svm_cm[0, :])\n",
    "    \n",
    "    # Calculate the average FPR and TNR\n",
    "    avg_fpr = (voting_fpr + svm_fpr) / 2\n",
    "    avg_tnr = (voting_tnr + svm_tnr) / 2\n",
    "    \n",
    "    # Aim to optimize both FPR and TNR\n",
    "    return avg_fpr + (1 - avg_tnr)\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S3 (RF+NBC) + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "import optuna\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_split': optuna.distributions.IntDistribution(2, 20),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "nbc_params = {\n",
    "    'var_smoothing': optuna.distributions.FloatDistribution(1e-10, 1e-1)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for Random Forest\n",
    "    rf_hyperparams = {\n",
    "        'n_estimators': trial.suggest_int('rf_n_estimators', 10, 70),\n",
    "        'max_depth': trial.suggest_int('rf_max_depth', 2, 32),\n",
    "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    # Define hyperparameters for GaussianNB\n",
    "    gnb_hyperparams = {\n",
    "        'var_smoothing': trial.suggest_float('gnb_var_smoothing', 1e-10, 1e-1, log=True)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    voting_classifier = VotingClassifier(\n",
    "        [(\"rf\", RandomForestClassifier(**rf_hyperparams)), (\"nbc\", GaussianNB(**gnb_hyperparams))],\n",
    "        voting='soft'\n",
    "    )\n",
    "    voting_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    voting_predicted = voting_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    # Calculate confusion matrices for both classifiers\n",
    "    voting_cm = confusion_matrix(y_validate_l1, voting_predicted)\n",
    "    svm_cm = confusion_matrix(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate False Positive Rates (FPR) and True Negative Rates (TNR) for both classifiers\n",
    "    rf_fpr = voting_cm[0, 1] / np.sum(voting_cm[0, :])\n",
    "    rf_tnr = voting_cm[0, 0] / np.sum(voting_cm[0, :])\n",
    "    \n",
    "    svm_fpr = svm_cm[0, 1] / np.sum(svm_cm[0, :])\n",
    "    svm_tnr = svm_cm[0, 0] / np.sum(svm_cm[0, :])\n",
    "    \n",
    "    # Calculate the average FPR and TNR\n",
    "    avg_fpr = (rf_fpr + svm_fpr) / 2\n",
    "    avg_tnr = (rf_tnr + svm_tnr) / 2\n",
    "    \n",
    "    # Aim to optimize both FPR and TNR\n",
    "    return avg_fpr + (1 - avg_tnr)\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S3 (HGBC+NBC) + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb_params = {\n",
    "    'learning_rate': optuna.distributions.FloatDistribution(0.001, 0.1),\n",
    "    'max_iter': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "nbc_params = {\n",
    "    'var_smoothing': optuna.distributions.FloatDistribution(1e-10, 1e-1)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for Random Forest\n",
    "    hgb_hyperparams = {\n",
    "        'learning_rate': trial.suggest_float('hgb_learning_rate', 0.001, 0.1, log=True),\n",
    "        'max_iter': trial.suggest_int('hgb_max_iter', 50, 500),\n",
    "        'max_depth': trial.suggest_int('hgb_max_depth', 2, 32),\n",
    "        'min_samples_leaf': trial.suggest_int('hgb_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    # Define hyperparameters for GaussianNB\n",
    "    gnb_hyperparams = {\n",
    "        'var_smoothing': trial.suggest_float('gnb_var_smoothing', 1e-10, 1e-1, log=True)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    voting_classifier = VotingClassifier(\n",
    "        [(\"hgbc\", HistGradientBoostingClassifier(**hgb_hyperparams)), (\"nbc\", GaussianNB(**gnb_hyperparams))],\n",
    "        voting='soft'\n",
    "    )\n",
    "    voting_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    voting_predicted = voting_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    # Calculate confusion matrices for both classifiers\n",
    "    voting_cm = confusion_matrix(y_validate_l1, voting_predicted)\n",
    "    svm_cm = confusion_matrix(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate False Positive Rates (FPR) and True Negative Rates (TNR) for both classifiers\n",
    "    rf_fpr = voting_cm[0, 1] / np.sum(voting_cm[0, :])\n",
    "    rf_tnr = voting_cm[0, 0] / np.sum(voting_cm[0, :])\n",
    "    \n",
    "    svm_fpr = svm_cm[0, 1] / np.sum(svm_cm[0, :])\n",
    "    svm_tnr = svm_cm[0, 0] / np.sum(svm_cm[0, :])\n",
    "    \n",
    "    # Calculate the average FPR and TNR\n",
    "    avg_fpr = (rf_fpr + svm_fpr) / 2\n",
    "    avg_tnr = (rf_tnr + svm_tnr) / 2\n",
    "    \n",
    "    # Aim to optimize both FPR and TNR\n",
    "    return avg_fpr + (1 - avg_tnr)\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S3 HGBC + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb_params = {\n",
    "    'learning_rate': optuna.distributions.FloatDistribution(0.001, 0.1),\n",
    "    'max_iter': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for Random Forest\n",
    "    hgb_hyperparams = {\n",
    "        'learning_rate': trial.suggest_float('hgb_learning_rate', 0.001, 0.1, log=True),\n",
    "        'max_iter': trial.suggest_int('hgb_max_iter', 50, 500),\n",
    "        'max_depth': trial.suggest_int('hgb_max_depth', 2, 32),\n",
    "        'min_samples_leaf': trial.suggest_int('hgb_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "   \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    hgb_classifier = HistGradientBoostingClassifier(**hgb_hyperparams)\n",
    "    hgb_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    hgb_predicted = hgb_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    # Calculate confusion matrices for both classifiers\n",
    "    hgb_cm = confusion_matrix(y_validate_l1, hgb_predicted)\n",
    "    svm_cm = confusion_matrix(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate False Positive Rates (FPR) and True Negative Rates (TNR) for both classifiers\n",
    "    rf_fpr = hgb_cm[0, 1] / np.sum(hgb_cm[0, :])\n",
    "    rf_tnr = hgb_cm[0, 0] / np.sum(hgb_cm[0, :])\n",
    "    \n",
    "    svm_fpr = svm_cm[0, 1] / np.sum(svm_cm[0, :])\n",
    "    svm_tnr = svm_cm[0, 0] / np.sum(svm_cm[0, :])\n",
    "    \n",
    "    # Calculate the average FPR and TNR\n",
    "    avg_fpr = (rf_fpr + svm_fpr) / 2\n",
    "    avg_tnr = (rf_tnr + svm_tnr) / 2\n",
    "    \n",
    "    # Aim to optimize both FPR and TNR\n",
    "    return avg_fpr + (1 - avg_tnr)\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S4 HGBC + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb_params = {\n",
    "    'learning_rate': optuna.distributions.FloatDistribution(0.001, 0.1),\n",
    "    'max_iter': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for Random Forest\n",
    "    hgb_hyperparams = {\n",
    "        'learning_rate': trial.suggest_float('hgb_learning_rate', 0.001, 0.1, log=True),\n",
    "        'max_iter': trial.suggest_int('hgb_max_iter', 50, 500),\n",
    "        'max_depth': trial.suggest_int('hgb_max_depth', 2, 32),\n",
    "        'min_samples_leaf': trial.suggest_int('hgb_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    hgb_classifier = HistGradientBoostingClassifier(**hgb_hyperparams)\n",
    "    hgb_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    hgb_predicted = hgb_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    # Calculate confusion matrices for both classifiers\n",
    "    hgb_cm = confusion_matrix(y_validate_l1, hgb_predicted)\n",
    "    svm_cm = confusion_matrix(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate Precision and False Negative Rate (FNR) for both classifiers\n",
    "    hgb_precision = hgb_cm[1, 1] / np.sum(hgb_cm[:, 1])\n",
    "    hgb_fnr = hgb_cm[1, 0] / np.sum(hgb_cm[1, :])\n",
    "    \n",
    "    svm_precision = svm_cm[1, 1] / np.sum(svm_cm[:, 1])\n",
    "    svm_fnr = svm_cm[1, 0] / np.sum(svm_cm[1, :])\n",
    "    \n",
    "    # Calculate the average Precision and FNR\n",
    "    avg_precision = (hgb_precision + svm_precision) / 2\n",
    "    avg_fnr = (hgb_fnr + svm_fnr) / 2\n",
    "    \n",
    "    # Aim to optimize both Precision and FNR\n",
    "    return 1 - (avg_precision + avg_fnr)  # Minimize the sum of Precision and FNR\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S4 (HGBC+NBC) + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb_params = {\n",
    "    'learning_rate': optuna.distributions.FloatDistribution(0.001, 0.1),\n",
    "    'max_iter': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "nbc_params = {\n",
    "    'var_smoothing': optuna.distributions.FloatDistribution(1e-10, 1e-1)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for Random Forest\n",
    "    hgb_hyperparams = {\n",
    "        'learning_rate': trial.suggest_float('hgb_learning_rate', 0.001, 0.1, log=True),\n",
    "        'max_iter': trial.suggest_int('hgb_max_iter', 50, 500),\n",
    "        'max_depth': trial.suggest_int('hgb_max_depth', 2, 32),\n",
    "        'min_samples_leaf': trial.suggest_int('hgb_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    # Define hyperparameters for GaussianNB\n",
    "    gnb_hyperparams = {\n",
    "        'var_smoothing': trial.suggest_float('gnb_var_smoothing', 1e-10, 1e-1, log=True)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    voting_classifier = VotingClassifier(\n",
    "        [(\"hgbc\", HistGradientBoostingClassifier(**hgb_hyperparams)), (\"nbc\", GaussianNB(**gnb_hyperparams))],\n",
    "        voting='soft'\n",
    "    )\n",
    "    voting_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    hgb_classifier = HistGradientBoostingClassifier(**hgb_hyperparams)\n",
    "    hgb_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    hgb_predicted = hgb_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    # Calculate confusion matrices for both classifiers\n",
    "    hgb_cm = confusion_matrix(y_validate_l1, hgb_predicted)\n",
    "    svm_cm = confusion_matrix(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate Precision and False Negative Rate (FNR) for both classifiers\n",
    "    hgb_precision = hgb_cm[1, 1] / np.sum(hgb_cm[:, 1])\n",
    "    hgb_fnr = hgb_cm[1, 0] / np.sum(hgb_cm[1, :])\n",
    "    \n",
    "    svm_precision = svm_cm[1, 1] / np.sum(svm_cm[:, 1])\n",
    "    svm_fnr = svm_cm[1, 0] / np.sum(svm_cm[1, :])\n",
    "    \n",
    "    # Calculate the average Precision and FNR\n",
    "    avg_precision = (hgb_precision + svm_precision) / 2\n",
    "    avg_fnr = (hgb_fnr + svm_fnr) / 2\n",
    "    \n",
    "    # Aim to optimize both Precision and FNR\n",
    "    return 1 - (avg_precision + avg_fnr)  # Minimize the sum of Precision and FNR\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S4 RF + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "import optuna\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_split': optuna.distributions.IntDistribution(2, 20),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for Random Forest\n",
    "    rf_hyperparams = {\n",
    "        'n_estimators': trial.suggest_int('rf_n_estimators', 10, 70),\n",
    "        'max_depth': trial.suggest_int('rf_max_depth', 2, 32),\n",
    "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    \"\"\"\n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \n",
    "    # Initialize and train Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(**rf_hyperparams)\n",
    "    rf_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    rf_predicted = rf_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    # Calculate confusion matrices for both classifiers\n",
    "    rf_cm = confusion_matrix(y_validate_l1, rf_predicted)\n",
    "    svm_cm = confusion_matrix(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate Precision and False Negative Rate (FNR) for both classifiers\n",
    "    rf_precision = rf_cm[1, 1] / np.sum(rf_cm[:, 1])\n",
    "    rf_fnr = rf_cm[1, 0] / np.sum(rf_cm[1, :])\n",
    "    \n",
    "    svm_precision = svm_cm[1, 1] / np.sum(svm_cm[:, 1])\n",
    "    svm_fnr = svm_cm[1, 0] / np.sum(svm_cm[1, :])\n",
    "    \n",
    "    # Calculate the average Precision and FNR\n",
    "    avg_precision = (rf_precision + svm_precision) / 2\n",
    "    avg_fnr = (rf_fnr + svm_fnr) / 2\n",
    "    \n",
    "    # Aim to optimize both Precision and FNR\n",
    "    return 1 - (avg_precision + avg_fnr)  # Minimize the sum of Precision and FNR\n",
    "    \n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# S4 (RF+NBC) + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "import optuna\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': optuna.distributions.IntDistribution(50, 500),\n",
    "    'max_depth': optuna.distributions.IntDistribution(2, 32),\n",
    "    'min_samples_split': optuna.distributions.IntDistribution(2, 20),\n",
    "    'min_samples_leaf': optuna.distributions.IntDistribution(1, 10)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': optuna.distributions.FloatDistribution(0.1, 10),\n",
    "    'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-2)\n",
    "}\n",
    "\n",
    "nbc_params = {\n",
    "    'var_smoothing': optuna.distributions.FloatDistribution(1e-10, 1e-1)\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters for Random Forest\n",
    "    rf_hyperparams = {\n",
    "        'n_estimators': trial.suggest_int('rf_n_estimators', 10, 70),\n",
    "        'max_depth': trial.suggest_int('rf_max_depth', 2, 32),\n",
    "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    # Define hyperparameters for GaussianNB\n",
    "    gnb_hyperparams = {\n",
    "        'var_smoothing': trial.suggest_float('gnb_var_smoothing', 1e-10, 1e-1, log=True)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 10),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 1e-6, 1e-2)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define hyperparameters for SVM\n",
    "    svm_hyperparams = {\n",
    "        'C': trial.suggest_float('svm_C', 0.1, 0.1),\n",
    "        'kernel': trial.suggest_categorical('svm_kernel', ['rbf']),\n",
    "        'gamma': trial.suggest_float('svm_gamma', 0.01, 0.01)\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    voting_classifier = VotingClassifier(\n",
    "        [(\"rf\", RandomForestClassifier(**rf_hyperparams)), (\"nbc\", GaussianNB(**gnb_hyperparams))],\n",
    "        voting='soft'\n",
    "    )\n",
    "    voting_classifier.fit(X_train_dos_probe, y_train_l1)\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    svm_classifier = SVC(**svm_hyperparams)\n",
    "    svm_classifier.fit(X_train_r2l_u2r, y_train_l2)\n",
    "    \n",
    "    # Predict on validation set and calculate metrics for both classifiers\n",
    "    voting_predicted = voting_classifier.predict(X_validate_dos_probe)\n",
    "    svm_predicted = svm_classifier.predict(X_validate_r2l_u2r)\n",
    "    \n",
    "    # Calculate confusion matrices for both classifiers\n",
    "    voting_cm = confusion_matrix(y_validate_l1, voting_predicted)\n",
    "    svm_cm = confusion_matrix(y_validate_l2, svm_predicted)\n",
    "    \n",
    "    # Calculate Precision and False Negative Rate (FNR) for both classifiers\n",
    "    voting_precision = voting_cm[1, 1] / np.sum(voting_cm[:, 1])\n",
    "    voting_fnr = voting_cm[1, 0] / np.sum(voting_cm[1, :])\n",
    "    \n",
    "    svm_precision = svm_cm[1, 1] / np.sum(svm_cm[:, 1])\n",
    "    svm_fnr = svm_cm[1, 0] / np.sum(svm_cm[1, :])\n",
    "    \n",
    "    # Calculate the average Precision and FNR\n",
    "    avg_precision = (voting_precision + svm_precision) / 2\n",
    "    avg_fnr = (voting_fnr + svm_fnr) / 2\n",
    "    \n",
    "    # Aim to optimize both Precision and FNR\n",
    "    return 1 - (avg_precision + avg_fnr)  # Minimize the sum of Precision and FNR\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "start = datetime.now()\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "tuning_time = datetime.now() - start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:08:58.955751Z",
     "start_time": "2024-03-06T16:08:58.947900800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning_time:  0:00:52.858972\n"
     ]
    }
   ],
   "source": [
    "print('tuning_time: ', tuning_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Get the best hyperparameters for RF + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_params1 = {\n",
    "    'n_estimators': study.best_trial.params['rf_n_estimators'],\n",
    "    'max_depth': study.best_trial.params['rf_max_depth'],\n",
    "    'min_samples_split': study.best_trial.params['rf_min_samples_split'],\n",
    "    'min_samples_leaf': study.best_trial.params['rf_min_samples_leaf']\n",
    "}\n",
    "\n",
    "best_params2 = {\n",
    "    'C': study.best_trial.params['svm_C'],\n",
    "    'kernel': study.best_trial.params['svm_kernel'],\n",
    "    'gamma': study.best_trial.params['svm_gamma']\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Get the best hyperparameters for HGBC + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "best_params1 = {\n",
    "    'learning_rate': study.best_trial.params['hgb_learning_rate'],\n",
    "    'max_depth': study.best_trial.params['hgb_max_depth'],\n",
    "    'max_iter': study.best_trial.params['hgb_max_iter'],\n",
    "    'min_samples_leaf': study.best_trial.params['hgb_min_samples_leaf']\n",
    "}\n",
    "\n",
    "best_params2 = {\n",
    "    'C': study.best_trial.params['svm_C'],\n",
    "    'kernel': study.best_trial.params['svm_kernel'],\n",
    "    'gamma': study.best_trial.params['svm_gamma']\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Get the best hyperparameters for (RF+NBC) + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "best_params1 = {\n",
    "    'n_estimators': study.best_trial.params['rf_n_estimators'],\n",
    "    'max_depth': study.best_trial.params['rf_max_depth'],\n",
    "    'min_samples_split': study.best_trial.params['rf_min_samples_split'],\n",
    "    'min_samples_leaf': study.best_trial.params['rf_min_samples_leaf']\n",
    "}\n",
    "\n",
    "best_params_nbc = {\n",
    "    'var_smoothing': study.best_trial.params['gnb_var_smoothing']\n",
    "}\n",
    "\n",
    "best_params2 = {\n",
    "    'C': study.best_trial.params['svm_C'],\n",
    "    'kernel': study.best_trial.params['svm_kernel'],\n",
    "    'gamma': study.best_trial.params['svm_gamma']\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print(best_params_nbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Get the best hyperparameters for (HGBC+NBC) + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "best_params1 = {\n",
    "    'learning_rate': study.best_trial.params['hgb_learning_rate'],\n",
    "    'max_depth': study.best_trial.params['hgb_max_depth'],\n",
    "    'max_iter': study.best_trial.params['hgb_max_iter'],\n",
    "    'min_samples_leaf': study.best_trial.params['hgb_min_samples_leaf']\n",
    "}\n",
    "\n",
    "best_params_nbc = {\n",
    "    'var_smoothing': study.best_trial.params['gnb_var_smoothing']\n",
    "}\n",
    "\n",
    "# Get the best hyperparameters for SVM\n",
    "best_params2 = {\n",
    "    'C': study.best_trial.params['svm_C'],\n",
    "    'kernel': study.best_trial.params['svm_kernel'],\n",
    "    'gamma': study.best_trial.params['svm_gamma']\n",
    "}\n",
    "\n",
    "print(best_params_nbc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:08:58.984378100Z",
     "start_time": "2024-03-06T16:08:58.955751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.011902278162232304, 'max_depth': 26, 'max_iter': 333, 'min_samples_leaf': 2} {'C': 2.809356359824321, 'kernel': 'linear', 'gamma': 0.000566316608859137}\n"
     ]
    }
   ],
   "source": [
    "print(best_params1, best_params2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train RF + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_classifier1 = RandomForestClassifier(**best_params1)\n",
    "best_classifier1.fit(X_train_dos_probe, y_train_l1)\n",
    "\n",
    "best_classifier2 = SVC(**best_params2)\n",
    "best_classifier2.fit(X_train_r2l_u2r, y_train_l2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train HGBC + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "best_classifier1 = HistGradientBoostingClassifier(**best_params1)\n",
    "best_classifier1.fit(X_train_dos_probe, y_train_l1)\n",
    "\n",
    "best_classifier2 = SVC(**best_params2)\n",
    "best_classifier2.fit(X_train_r2l_u2r, y_train_l2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train (RF+NBC) + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "best_classifier1 = VotingClassifier(\n",
    "    [(\"rf\", RandomForestClassifier(**best_params1)), (\"nbc\", GaussianNB(**best_params_nbc))],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "best_classifier2 = SVC(**best_params2)\n",
    "\n",
    "best_classifier1.fit(X_train_dos_probe, y_train_l1)\n",
    "best_classifier2.fit(X_train_r2l_u2r, y_train_l2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train (HGBC+NBC) + SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "best_classifier1 = VotingClassifier(\n",
    "    [(\"hgbc\", HistGradientBoostingClassifier(**best_params1)), (\"nbc\", GaussianNB(**best_params_nbc))],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "best_classifier2 = SVC(**best_params2)\n",
    "\n",
    "best_classifier1.fit(X_train_dos_probe, y_train_l1)\n",
    "best_classifier2.fit(X_train_r2l_u2r, y_train_l2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "outputs": [],
   "source": [
    "classifier1 = best_classifier1\n",
    "classifier2 = best_classifier2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:09:02.052771400Z",
     "start_time": "2024-03-06T16:09:02.046571600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:10:14.499030400Z",
     "start_time": "2024-03-06T16:09:02.050725300Z"
    }
   },
   "outputs": [],
   "source": [
    "# the results may vary\n",
    "accuracy, f_score, precision, recall, clf_time, tnr, fpr, fnr, result = test_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.8510024840312278\n",
      "F1 Score =  0.8544312026002167\n",
      "Precision =  0.9625073227885179\n",
      "Recall =  0.7681757967739422\n",
      "True Negative Rate (TNR) = 0.9604572134692617\n",
      "False Positive Rate (FPR) = 0.03954278653073834\n",
      "False Negative Rate (FNR) = 0.23182420322605782\n",
      "Classification time =  0:01:12.392076\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy = ', accuracy)\n",
    "print('F1 Score = ', f_score)\n",
    "print('Precision = ', precision)\n",
    "print('Recall = ', recall)\n",
    "print('True Negative Rate (TNR) =', tnr)\n",
    "print('False Positive Rate (FPR) =', fpr)\n",
    "\n",
    "print('False Negative Rate (FNR) =', fnr)\n",
    "\n",
    "print('Classification time = ', clf_time)"
   ],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:10:14.509369200Z",
     "start_time": "2024-03-06T16:10:14.499030400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC graph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test_real, result)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.savefig('static_roc_curve-hgbc.png')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T16:10:14.746284600Z",
     "start_time": "2024-03-06T16:10:14.504180800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Export the test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "if True:\n",
    "    column_names = [f'PC{i}' for i in range(1, X_test_layer1.shape[1] + 1)]\n",
    "    X1_test = pd.DataFrame(data=X_test_layer1, columns=column_names)\n",
    "    X1_test.to_csv('EvalResources/AdditionalSets/x_test_l1_pca.txt', index=False)\n",
    "    \n",
    "    column_names = [f'PC{i}' for i in range(1, X_test_layer2.shape[1] + 1)]\n",
    "    X2_test = pd.DataFrame(data=X_test_layer2, columns=column_names)\n",
    "    X2_test.to_csv('EvalResources/AdditionalSets/x_test_l2_pca.txt', index=False)\n",
    "    \n",
    "    np.save('EvalResources/AdditionalSets/y_test', y_test_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate seen and unseen attack categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:10:14.870508400Z",
     "start_time": "2024-03-06T16:10:14.746284600Z"
    }
   },
   "outputs": [],
   "source": [
    "# load testset\n",
    "df_test = pd.read_csv('EvalResources/KDDTest+.txt', sep=\",\", header=None, skipinitialspace = True)\n",
    "df_test = df_test[df_test.columns[:-1]]\n",
    "df_test.columns = titles.to_list()\n",
    "y_test = df_test['label']\n",
    "df_test = df_test.drop(['num_outbound_cmds'],axis=1)\n",
    "\n",
    "df_test_original = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "if EXPORT_DATASETS:\n",
    "    df_test_original.to_csv('EvalResources/ProcessedDatasets/x_test_full.txt', index=False)\n",
    "    np.save('EvalResources/ProcessedDatasets/y_test_full', y_test)\n",
    "    \n",
    "#df_test_original"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:10:14.994903700Z",
     "start_time": "2024-03-06T16:10:14.862998600Z"
    }
   },
   "outputs": [],
   "source": [
    "new_attack = []\n",
    "for i in df_test_original['label'].value_counts().index.tolist()[1:]:\n",
    "    if i not in df_train_original['label'].value_counts().index.tolist()[1:]:\n",
    "        new_attack.append(i)\n",
    "        \n",
    "new_attack.sort()\n",
    "#new_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:10:15.082601600Z",
     "start_time": "2024-03-06T16:10:15.017377800Z"
    }
   },
   "outputs": [],
   "source": [
    "index_of_new_attacks = []\n",
    "\n",
    "for i in range(len(df_test_original)):\n",
    "    if df_test_original['label'][i] in new_attack:\n",
    "        index_of_new_attacks.append(df_test_original.index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:10:15.107229700Z",
     "start_time": "2024-03-06T16:10:15.081022300Z"
    }
   },
   "outputs": [],
   "source": [
    "#len(index_of_new_attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:10:15.110346400Z",
     "start_time": "2024-03-06T16:10:15.086592800Z"
    }
   },
   "outputs": [],
   "source": [
    "new_attack.append('normal')\n",
    "#new_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:10:15.264056900Z",
     "start_time": "2024-03-06T16:10:15.090176200Z"
    }
   },
   "outputs": [],
   "source": [
    "index_of_old_attacks = []\n",
    "\n",
    "for i in range(len(df_test_original)):\n",
    "    if df_test_original['label'][i] not in new_attack:\n",
    "        index_of_old_attacks.append(df_test_original.index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:10:15.283395300Z",
     "start_time": "2024-03-06T16:10:15.245938200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new attacks in the test set:  3750\n",
      "Number of new attacks detected by the classifiers:  1977\n",
      "Proportion of new attacks detected:  0.5272\n"
     ]
    }
   ],
   "source": [
    "print('Number of new attacks in the test set: ', result[index_of_new_attacks].shape[0])\n",
    "print('Number of new attacks detected by the classifiers: ', result[index_of_new_attacks].sum())\n",
    "print('Proportion of new attacks detected: ', result[index_of_new_attacks].sum()/result[index_of_new_attacks].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:10:15.371172600Z",
     "start_time": "2024-03-06T16:10:15.252251600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of old attacks in the test set:  9083\n",
      "Number of old attacks detected by the classifiers:  7881\n",
      "Proportion of old attacks detected:  0.8676648684355389\n"
     ]
    }
   ],
   "source": [
    "print('Number of old attacks in the test set: ', result[index_of_old_attacks].shape[0])\n",
    "print('Number of old attacks detected by the classifiers: ', result[index_of_old_attacks].sum())\n",
    "print('Proportion of old attacks detected: ', result[index_of_old_attacks].sum()/result[index_of_old_attacks].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate single attack types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T16:10:15.466457500Z",
     "start_time": "2024-03-06T16:10:15.298923300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio DOS of detection:  0.8280160857908847\n",
      "Ratio PROBE of detection:  0.9124328789756299\n",
      "Ratio U2R of detection:  0.4908145580589255\n",
      "Ratio R2L of detection:  0.835820895522388\n",
      "New attacks detected:  0.5272\n",
      "Old attacks detected:  0.8676648684355389\n"
     ]
    }
   ],
   "source": [
    "# load test set\n",
    "df_test = pd.read_csv('EvalResources/KDDTest+.txt', sep=\",\", header=None, skipinitialspace = True)\n",
    "df_test = df_test[df_test.columns[:-1]]\n",
    "df_test.columns = titles.to_list()\n",
    "y_test = df_test['label']\n",
    "df_test = df_test.drop(['num_outbound_cmds'],axis=1)\n",
    "df_test_original = df_test\n",
    "df = df_test_original\n",
    "\n",
    "dos_index = df.index[(df['label'].isin(dos_attacks))].tolist()\n",
    "probe_index = df.index[(df['label'].isin(probe_attacks))].tolist()\n",
    "r2l_index = df.index[(df['label'].isin(r2l_attacks))].tolist()\n",
    "u2r_index = df.index[(df['label'].isin(u2r_attacks))].tolist()\n",
    "\n",
    "print(\"Ratio DOS of detection: \", result[dos_index].sum()/result[dos_index].shape[0])\n",
    "\n",
    "print(\"Ratio PROBE of detection: \", result[probe_index].sum()/result[probe_index].shape[0])\n",
    "\n",
    "print(\"Ratio U2R of detection: \", result[r2l_index].sum()/result[r2l_index].shape[0])\n",
    "\n",
    "print(\"Ratio R2L of detection: \", result[u2r_index].sum()/result[u2r_index].shape[0])\n",
    "\n",
    "print('New attacks detected: ', result[index_of_new_attacks].sum()/result[index_of_new_attacks].shape[0])\n",
    "\n",
    "print('Old attacks detected: ', result[index_of_old_attacks].sum()/result[index_of_old_attacks].shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
